/* automatically generated by rust-bindgen 0.63.0 */

pub const _STDINT_H: u32 = 1;
pub const _FEATURES_H: u32 = 1;
pub const _DEFAULT_SOURCE: u32 = 1;
pub const __GLIBC_USE_ISOC2X: u32 = 0;
pub const __USE_ISOC11: u32 = 1;
pub const __USE_ISOC99: u32 = 1;
pub const __USE_ISOC95: u32 = 1;
pub const __USE_POSIX_IMPLICITLY: u32 = 1;
pub const _POSIX_SOURCE: u32 = 1;
pub const _POSIX_C_SOURCE: u32 = 200809;
pub const __USE_POSIX: u32 = 1;
pub const __USE_POSIX2: u32 = 1;
pub const __USE_POSIX199309: u32 = 1;
pub const __USE_POSIX199506: u32 = 1;
pub const __USE_XOPEN2K: u32 = 1;
pub const __USE_XOPEN2K8: u32 = 1;
pub const _ATFILE_SOURCE: u32 = 1;
pub const __USE_MISC: u32 = 1;
pub const __USE_ATFILE: u32 = 1;
pub const __USE_FORTIFY_LEVEL: u32 = 0;
pub const __GLIBC_USE_DEPRECATED_GETS: u32 = 0;
pub const __GLIBC_USE_DEPRECATED_SCANF: u32 = 0;
pub const _STDC_PREDEF_H: u32 = 1;
pub const __STDC_IEC_559__: u32 = 1;
pub const __STDC_IEC_559_COMPLEX__: u32 = 1;
pub const __STDC_ISO_10646__: u32 = 201706;
pub const __GNU_LIBRARY__: u32 = 6;
pub const __GLIBC__: u32 = 2;
pub const __GLIBC_MINOR__: u32 = 31;
pub const _SYS_CDEFS_H: u32 = 1;
pub const __glibc_c99_flexarr_available: u32 = 1;
pub const __WORDSIZE: u32 = 64;
pub const __WORDSIZE_TIME64_COMPAT32: u32 = 1;
pub const __SYSCALL_WORDSIZE: u32 = 64;
pub const __LONG_DOUBLE_USES_FLOAT128: u32 = 0;
pub const __HAVE_GENERIC_SELECTION: u32 = 1;
pub const __GLIBC_USE_LIB_EXT2: u32 = 0;
pub const __GLIBC_USE_IEC_60559_BFP_EXT: u32 = 0;
pub const __GLIBC_USE_IEC_60559_BFP_EXT_C2X: u32 = 0;
pub const __GLIBC_USE_IEC_60559_FUNCS_EXT: u32 = 0;
pub const __GLIBC_USE_IEC_60559_FUNCS_EXT_C2X: u32 = 0;
pub const __GLIBC_USE_IEC_60559_TYPES_EXT: u32 = 0;
pub const _BITS_TYPES_H: u32 = 1;
pub const __TIMESIZE: u32 = 64;
pub const _BITS_TYPESIZES_H: u32 = 1;
pub const __OFF_T_MATCHES_OFF64_T: u32 = 1;
pub const __INO_T_MATCHES_INO64_T: u32 = 1;
pub const __RLIM_T_MATCHES_RLIM64_T: u32 = 1;
pub const __STATFS_MATCHES_STATFS64: u32 = 1;
pub const __FD_SETSIZE: u32 = 1024;
pub const _BITS_TIME64_H: u32 = 1;
pub const _BITS_WCHAR_H: u32 = 1;
pub const _BITS_STDINT_INTN_H: u32 = 1;
pub const _BITS_STDINT_UINTN_H: u32 = 1;
pub const INT8_MIN: i32 = -128;
pub const INT16_MIN: i32 = -32768;
pub const INT32_MIN: i32 = -2147483648;
pub const INT8_MAX: u32 = 127;
pub const INT16_MAX: u32 = 32767;
pub const INT32_MAX: u32 = 2147483647;
pub const UINT8_MAX: u32 = 255;
pub const UINT16_MAX: u32 = 65535;
pub const UINT32_MAX: u32 = 4294967295;
pub const INT_LEAST8_MIN: i32 = -128;
pub const INT_LEAST16_MIN: i32 = -32768;
pub const INT_LEAST32_MIN: i32 = -2147483648;
pub const INT_LEAST8_MAX: u32 = 127;
pub const INT_LEAST16_MAX: u32 = 32767;
pub const INT_LEAST32_MAX: u32 = 2147483647;
pub const UINT_LEAST8_MAX: u32 = 255;
pub const UINT_LEAST16_MAX: u32 = 65535;
pub const UINT_LEAST32_MAX: u32 = 4294967295;
pub const INT_FAST8_MIN: i32 = -128;
pub const INT_FAST16_MIN: i64 = -9223372036854775808;
pub const INT_FAST32_MIN: i64 = -9223372036854775808;
pub const INT_FAST8_MAX: u32 = 127;
pub const INT_FAST16_MAX: u64 = 9223372036854775807;
pub const INT_FAST32_MAX: u64 = 9223372036854775807;
pub const UINT_FAST8_MAX: u32 = 255;
pub const UINT_FAST16_MAX: i32 = -1;
pub const UINT_FAST32_MAX: i32 = -1;
pub const INTPTR_MIN: i64 = -9223372036854775808;
pub const INTPTR_MAX: u64 = 9223372036854775807;
pub const UINTPTR_MAX: i32 = -1;
pub const PTRDIFF_MIN: i64 = -9223372036854775808;
pub const PTRDIFF_MAX: u64 = 9223372036854775807;
pub const SIG_ATOMIC_MIN: i32 = -2147483648;
pub const SIG_ATOMIC_MAX: u32 = 2147483647;
pub const SIZE_MAX: i32 = -1;
pub const WINT_MIN: u32 = 0;
pub const WINT_MAX: u32 = 4294967295;
pub const true_: u32 = 1;
pub const false_: u32 = 0;
pub const __bool_true_false_are_defined: u32 = 1;
pub const TRITONSERVER_API_VERSION_MAJOR: u32 = 1;
pub const TRITONSERVER_API_VERSION_MINOR: u32 = 17;
pub const TRITONBACKEND_API_VERSION_MAJOR: u32 = 1;
pub const TRITONBACKEND_API_VERSION_MINOR: u32 = 11;
pub type wchar_t = ::std::os::raw::c_int;
#[repr(C)]
#[repr(align(16))]
#[derive(Debug, Copy, Clone)]
pub struct max_align_t {
    pub __clang_max_align_nonce1: ::std::os::raw::c_longlong,
    pub __bindgen_padding_0: u64,
    pub __clang_max_align_nonce2: u128,
}
#[test]
fn bindgen_test_layout_max_align_t() {
    const UNINIT: ::std::mem::MaybeUninit<max_align_t> = ::std::mem::MaybeUninit::uninit();
    let ptr = UNINIT.as_ptr();
    assert_eq!(
        ::std::mem::size_of::<max_align_t>(),
        32usize,
        concat!("Size of: ", stringify!(max_align_t))
    );
    assert_eq!(
        ::std::mem::align_of::<max_align_t>(),
        16usize,
        concat!("Alignment of ", stringify!(max_align_t))
    );
    assert_eq!(
        unsafe { ::std::ptr::addr_of!((*ptr).__clang_max_align_nonce1) as usize - ptr as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(max_align_t),
            "::",
            stringify!(__clang_max_align_nonce1)
        )
    );
    assert_eq!(
        unsafe { ::std::ptr::addr_of!((*ptr).__clang_max_align_nonce2) as usize - ptr as usize },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(max_align_t),
            "::",
            stringify!(__clang_max_align_nonce2)
        )
    );
}
pub type __u_char = ::std::os::raw::c_uchar;
pub type __u_short = ::std::os::raw::c_ushort;
pub type __u_int = ::std::os::raw::c_uint;
pub type __u_long = ::std::os::raw::c_ulong;
pub type __int8_t = ::std::os::raw::c_schar;
pub type __uint8_t = ::std::os::raw::c_uchar;
pub type __int16_t = ::std::os::raw::c_short;
pub type __uint16_t = ::std::os::raw::c_ushort;
pub type __int32_t = ::std::os::raw::c_int;
pub type __uint32_t = ::std::os::raw::c_uint;
pub type __int64_t = ::std::os::raw::c_long;
pub type __uint64_t = ::std::os::raw::c_ulong;
pub type __int_least8_t = __int8_t;
pub type __uint_least8_t = __uint8_t;
pub type __int_least16_t = __int16_t;
pub type __uint_least16_t = __uint16_t;
pub type __int_least32_t = __int32_t;
pub type __uint_least32_t = __uint32_t;
pub type __int_least64_t = __int64_t;
pub type __uint_least64_t = __uint64_t;
pub type __quad_t = ::std::os::raw::c_long;
pub type __u_quad_t = ::std::os::raw::c_ulong;
pub type __intmax_t = ::std::os::raw::c_long;
pub type __uintmax_t = ::std::os::raw::c_ulong;
pub type __dev_t = ::std::os::raw::c_ulong;
pub type __uid_t = ::std::os::raw::c_uint;
pub type __gid_t = ::std::os::raw::c_uint;
pub type __ino_t = ::std::os::raw::c_ulong;
pub type __ino64_t = ::std::os::raw::c_ulong;
pub type __mode_t = ::std::os::raw::c_uint;
pub type __nlink_t = ::std::os::raw::c_ulong;
pub type __off_t = ::std::os::raw::c_long;
pub type __off64_t = ::std::os::raw::c_long;
pub type __pid_t = ::std::os::raw::c_int;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __fsid_t {
    pub __val: [::std::os::raw::c_int; 2usize],
}
#[test]
fn bindgen_test_layout___fsid_t() {
    const UNINIT: ::std::mem::MaybeUninit<__fsid_t> = ::std::mem::MaybeUninit::uninit();
    let ptr = UNINIT.as_ptr();
    assert_eq!(
        ::std::mem::size_of::<__fsid_t>(),
        8usize,
        concat!("Size of: ", stringify!(__fsid_t))
    );
    assert_eq!(
        ::std::mem::align_of::<__fsid_t>(),
        4usize,
        concat!("Alignment of ", stringify!(__fsid_t))
    );
    assert_eq!(
        unsafe { ::std::ptr::addr_of!((*ptr).__val) as usize - ptr as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(__fsid_t),
            "::",
            stringify!(__val)
        )
    );
}
pub type __clock_t = ::std::os::raw::c_long;
pub type __rlim_t = ::std::os::raw::c_ulong;
pub type __rlim64_t = ::std::os::raw::c_ulong;
pub type __id_t = ::std::os::raw::c_uint;
pub type __time_t = ::std::os::raw::c_long;
pub type __useconds_t = ::std::os::raw::c_uint;
pub type __suseconds_t = ::std::os::raw::c_long;
pub type __daddr_t = ::std::os::raw::c_int;
pub type __key_t = ::std::os::raw::c_int;
pub type __clockid_t = ::std::os::raw::c_int;
pub type __timer_t = *mut ::std::os::raw::c_void;
pub type __blksize_t = ::std::os::raw::c_long;
pub type __blkcnt_t = ::std::os::raw::c_long;
pub type __blkcnt64_t = ::std::os::raw::c_long;
pub type __fsblkcnt_t = ::std::os::raw::c_ulong;
pub type __fsblkcnt64_t = ::std::os::raw::c_ulong;
pub type __fsfilcnt_t = ::std::os::raw::c_ulong;
pub type __fsfilcnt64_t = ::std::os::raw::c_ulong;
pub type __fsword_t = ::std::os::raw::c_long;
pub type __ssize_t = ::std::os::raw::c_long;
pub type __syscall_slong_t = ::std::os::raw::c_long;
pub type __syscall_ulong_t = ::std::os::raw::c_ulong;
pub type __loff_t = __off64_t;
pub type __caddr_t = *mut ::std::os::raw::c_char;
pub type __intptr_t = ::std::os::raw::c_long;
pub type __socklen_t = ::std::os::raw::c_uint;
pub type __sig_atomic_t = ::std::os::raw::c_int;
pub type int_least8_t = __int_least8_t;
pub type int_least16_t = __int_least16_t;
pub type int_least32_t = __int_least32_t;
pub type int_least64_t = __int_least64_t;
pub type uint_least8_t = __uint_least8_t;
pub type uint_least16_t = __uint_least16_t;
pub type uint_least32_t = __uint_least32_t;
pub type uint_least64_t = __uint_least64_t;
pub type int_fast8_t = ::std::os::raw::c_schar;
pub type int_fast16_t = ::std::os::raw::c_long;
pub type int_fast32_t = ::std::os::raw::c_long;
pub type int_fast64_t = ::std::os::raw::c_long;
pub type uint_fast8_t = ::std::os::raw::c_uchar;
pub type uint_fast16_t = ::std::os::raw::c_ulong;
pub type uint_fast32_t = ::std::os::raw::c_ulong;
pub type uint_fast64_t = ::std::os::raw::c_ulong;
pub type intmax_t = __intmax_t;
pub type uintmax_t = __uintmax_t;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_BufferAttributes {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_Error {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_InferenceRequest {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_InferenceResponse {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_InferenceTrace {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_Message {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_Metrics {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_Parameter {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_ResponseAllocator {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_Server {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_ServerOptions {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_Metric {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_MetricFamily {
    _unused: [u8; 0],
}
extern "C" {
    #[doc = " Get the TRITONBACKEND API version supported by the Triton shared\n library. This value can be compared against the\n TRITONSERVER_API_VERSION_MAJOR and TRITONSERVER_API_VERSION_MINOR\n used to build the client to ensure that Triton shared library is\n compatible with the client.\n\n \\param major Returns the TRITONSERVER API major version supported\n by Triton.\n \\param minor Returns the TRITONSERVER API minor version supported\n by Triton.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ApiVersion(major: *mut u32, minor: *mut u32) -> *mut TRITONSERVER_Error;
}
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_INVALID: TRITONSERVER_datatype_enum = 0;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_BOOL: TRITONSERVER_datatype_enum = 1;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_UINT8: TRITONSERVER_datatype_enum = 2;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_UINT16: TRITONSERVER_datatype_enum = 3;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_UINT32: TRITONSERVER_datatype_enum = 4;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_UINT64: TRITONSERVER_datatype_enum = 5;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_INT8: TRITONSERVER_datatype_enum = 6;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_INT16: TRITONSERVER_datatype_enum = 7;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_INT32: TRITONSERVER_datatype_enum = 8;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_INT64: TRITONSERVER_datatype_enum = 9;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_FP16: TRITONSERVER_datatype_enum = 10;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_FP32: TRITONSERVER_datatype_enum = 11;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_FP64: TRITONSERVER_datatype_enum = 12;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_BYTES: TRITONSERVER_datatype_enum = 13;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_BF16: TRITONSERVER_datatype_enum = 14;
#[doc = " TRITONSERVER_DataType\n\n Tensor data types recognized by TRITONSERVER.\n"]
pub type TRITONSERVER_datatype_enum = ::std::os::raw::c_uint;
#[doc = " TRITONSERVER_DataType\n\n Tensor data types recognized by TRITONSERVER.\n"]
pub use self::TRITONSERVER_datatype_enum as TRITONSERVER_DataType;
extern "C" {
    #[doc = " Get the string representation of a data type. The returned string\n is not owned by the caller and so should not be modified or freed.\n\n \\param datatype The data type.\n \\return The string representation of the data type."]
    pub fn TRITONSERVER_DataTypeString(
        datatype: TRITONSERVER_DataType,
    ) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Get the Triton datatype corresponding to a string representation\n of a datatype.\n\n \\param dtype The datatype string representation.\n \\return The Triton data type or TRITONSERVER_TYPE_INVALID if the\n string does not represent a data type."]
    pub fn TRITONSERVER_StringToDataType(
        dtype: *const ::std::os::raw::c_char,
    ) -> TRITONSERVER_DataType;
}
extern "C" {
    #[doc = " Get the size of a Triton datatype in bytes. Zero is returned for\n TRITONSERVER_TYPE_BYTES because it have variable size. Zero is\n returned for TRITONSERVER_TYPE_INVALID.\n\n \\param dtype The datatype.\n \\return The size of the datatype."]
    pub fn TRITONSERVER_DataTypeByteSize(datatype: TRITONSERVER_DataType) -> u32;
}
pub const TRITONSERVER_memorytype_enum_TRITONSERVER_MEMORY_CPU: TRITONSERVER_memorytype_enum = 0;
pub const TRITONSERVER_memorytype_enum_TRITONSERVER_MEMORY_CPU_PINNED:
    TRITONSERVER_memorytype_enum = 1;
pub const TRITONSERVER_memorytype_enum_TRITONSERVER_MEMORY_GPU: TRITONSERVER_memorytype_enum = 2;
#[doc = " TRITONSERVER_MemoryType\n\n Types of memory recognized by TRITONSERVER.\n"]
pub type TRITONSERVER_memorytype_enum = ::std::os::raw::c_uint;
#[doc = " TRITONSERVER_MemoryType\n\n Types of memory recognized by TRITONSERVER.\n"]
pub use self::TRITONSERVER_memorytype_enum as TRITONSERVER_MemoryType;
extern "C" {
    #[doc = " Get the string representation of a memory type. The returned\n string is not owned by the caller and so should not be modified or\n freed.\n\n \\param memtype The memory type.\n \\return The string representation of the memory type."]
    pub fn TRITONSERVER_MemoryTypeString(
        memtype: TRITONSERVER_MemoryType,
    ) -> *const ::std::os::raw::c_char;
}
pub const TRITONSERVER_parametertype_enum_TRITONSERVER_PARAMETER_STRING:
    TRITONSERVER_parametertype_enum = 0;
pub const TRITONSERVER_parametertype_enum_TRITONSERVER_PARAMETER_INT:
    TRITONSERVER_parametertype_enum = 1;
pub const TRITONSERVER_parametertype_enum_TRITONSERVER_PARAMETER_BOOL:
    TRITONSERVER_parametertype_enum = 2;
pub const TRITONSERVER_parametertype_enum_TRITONSERVER_PARAMETER_BYTES:
    TRITONSERVER_parametertype_enum = 3;
#[doc = " TRITONSERVER_ParameterType\n\n Types of parameters recognized by TRITONSERVER.\n"]
pub type TRITONSERVER_parametertype_enum = ::std::os::raw::c_uint;
#[doc = " TRITONSERVER_ParameterType\n\n Types of parameters recognized by TRITONSERVER.\n"]
pub use self::TRITONSERVER_parametertype_enum as TRITONSERVER_ParameterType;
extern "C" {
    #[doc = " Get the string representation of a parameter type. The returned\n string is not owned by the caller and so should not be modified or\n freed.\n\n \\param paramtype The parameter type.\n \\return The string representation of the parameter type."]
    pub fn TRITONSERVER_ParameterTypeString(
        paramtype: TRITONSERVER_ParameterType,
    ) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Create a new parameter object. The caller takes ownership of the\n TRITONSERVER_Parameter object and must call TRITONSERVER_ParameterDelete to\n release the object. The object will maintain its own copy of the 'value'\n\n \\param name The parameter name.\n \\param type The parameter type.\n \\param value The pointer to the value.\n \\return A new TRITONSERVER_Parameter object. 'nullptr' will be returned if\n 'type' is 'TRITONSERVER_PARAMETER_BYTES'. The caller should use\n TRITONSERVER_ParameterBytesNew to create parameter with bytes type."]
    pub fn TRITONSERVER_ParameterNew(
        name: *const ::std::os::raw::c_char,
        type_: TRITONSERVER_ParameterType,
        value: *const ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Parameter;
}
extern "C" {
    #[doc = " Create a new parameter object with type TRITONSERVER_PARAMETER_BYTES.\n The caller takes ownership of the TRITONSERVER_Parameter object and must\n call TRITONSERVER_ParameterDelete to release the object. The object only\n maintains a shallow copy of the 'byte_ptr' so the data content must be\n valid until the parameter object is deleted.\n\n \\param name The parameter name.\n \\param byte_ptr The pointer to the data content.\n \\param size The size of the data content.\n \\return A new TRITONSERVER_Error object."]
    pub fn TRITONSERVER_ParameterBytesNew(
        name: *const ::std::os::raw::c_char,
        byte_ptr: *const ::std::os::raw::c_void,
        size: u64,
    ) -> *mut TRITONSERVER_Parameter;
}
extern "C" {
    #[doc = " Delete an parameter object.\n\n \\param parameter The parameter object."]
    pub fn TRITONSERVER_ParameterDelete(parameter: *mut TRITONSERVER_Parameter);
}
pub const TRITONSERVER_instancegroupkind_enum_TRITONSERVER_INSTANCEGROUPKIND_AUTO:
    TRITONSERVER_instancegroupkind_enum = 0;
pub const TRITONSERVER_instancegroupkind_enum_TRITONSERVER_INSTANCEGROUPKIND_CPU:
    TRITONSERVER_instancegroupkind_enum = 1;
pub const TRITONSERVER_instancegroupkind_enum_TRITONSERVER_INSTANCEGROUPKIND_GPU:
    TRITONSERVER_instancegroupkind_enum = 2;
pub const TRITONSERVER_instancegroupkind_enum_TRITONSERVER_INSTANCEGROUPKIND_MODEL:
    TRITONSERVER_instancegroupkind_enum = 3;
#[doc = " TRITONSERVER_InstanceGroupKind\n\n Kinds of instance groups recognized by TRITONSERVER.\n"]
pub type TRITONSERVER_instancegroupkind_enum = ::std::os::raw::c_uint;
#[doc = " TRITONSERVER_InstanceGroupKind\n\n Kinds of instance groups recognized by TRITONSERVER.\n"]
pub use self::TRITONSERVER_instancegroupkind_enum as TRITONSERVER_InstanceGroupKind;
extern "C" {
    #[doc = " Get the string representation of an instance-group kind. The\n returned string is not owned by the caller and so should not be\n modified or freed.\n\n \\param kind The instance-group kind.\n \\return The string representation of the kind."]
    pub fn TRITONSERVER_InstanceGroupKindString(
        kind: TRITONSERVER_InstanceGroupKind,
    ) -> *const ::std::os::raw::c_char;
}
pub const TRITONSERVER_loglevel_enum_TRITONSERVER_LOG_INFO: TRITONSERVER_loglevel_enum = 0;
pub const TRITONSERVER_loglevel_enum_TRITONSERVER_LOG_WARN: TRITONSERVER_loglevel_enum = 1;
pub const TRITONSERVER_loglevel_enum_TRITONSERVER_LOG_ERROR: TRITONSERVER_loglevel_enum = 2;
pub const TRITONSERVER_loglevel_enum_TRITONSERVER_LOG_VERBOSE: TRITONSERVER_loglevel_enum = 3;
#[doc = " TRITONSERVER_Logging\n\n Types/levels of logging.\n"]
pub type TRITONSERVER_loglevel_enum = ::std::os::raw::c_uint;
#[doc = " TRITONSERVER_Logging\n\n Types/levels of logging.\n"]
pub use self::TRITONSERVER_loglevel_enum as TRITONSERVER_LogLevel;
pub const TRITONSERVER_logformat_enum_TRITONSERVER_LOG_DEFAULT: TRITONSERVER_logformat_enum = 0;
pub const TRITONSERVER_logformat_enum_TRITONSERVER_LOG_ISO8601: TRITONSERVER_logformat_enum = 1;
#[doc = "\n Format of logging.\n\n TRITONSERVER_LOG_DEFAULT: the log severity (L) and timestamp will be\n logged as \"LMMDD hh:mm:ss.ssssss\".\n\n TRITONSERVER_LOG_ISO8601: the log format will be \"YYYY-MM-DDThh:mm:ssZ L\".\n"]
pub type TRITONSERVER_logformat_enum = ::std::os::raw::c_uint;
#[doc = "\n Format of logging.\n\n TRITONSERVER_LOG_DEFAULT: the log severity (L) and timestamp will be\n logged as \"LMMDD hh:mm:ss.ssssss\".\n\n TRITONSERVER_LOG_ISO8601: the log format will be \"YYYY-MM-DDThh:mm:ssZ L\".\n"]
pub use self::TRITONSERVER_logformat_enum as TRITONSERVER_LogFormat;
extern "C" {
    #[doc = " Is a log level enabled?\n\n \\param level The log level.\n \\return True if the log level is enabled, false if not enabled."]
    pub fn TRITONSERVER_LogIsEnabled(level: TRITONSERVER_LogLevel) -> bool;
}
extern "C" {
    #[doc = " Log a message at a given log level if that level is enabled.\n\n \\param level The log level.\n \\param filename The file name of the location of the log message.\n \\param line The line number of the log message.\n \\param msg The log message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_LogMessage(
        level: TRITONSERVER_LogLevel,
        filename: *const ::std::os::raw::c_char,
        line: ::std::os::raw::c_int,
        msg: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
pub const TRITONSERVER_errorcode_enum_TRITONSERVER_ERROR_UNKNOWN: TRITONSERVER_errorcode_enum = 0;
pub const TRITONSERVER_errorcode_enum_TRITONSERVER_ERROR_INTERNAL: TRITONSERVER_errorcode_enum = 1;
pub const TRITONSERVER_errorcode_enum_TRITONSERVER_ERROR_NOT_FOUND: TRITONSERVER_errorcode_enum = 2;
pub const TRITONSERVER_errorcode_enum_TRITONSERVER_ERROR_INVALID_ARG: TRITONSERVER_errorcode_enum =
    3;
pub const TRITONSERVER_errorcode_enum_TRITONSERVER_ERROR_UNAVAILABLE: TRITONSERVER_errorcode_enum =
    4;
pub const TRITONSERVER_errorcode_enum_TRITONSERVER_ERROR_UNSUPPORTED: TRITONSERVER_errorcode_enum =
    5;
pub const TRITONSERVER_errorcode_enum_TRITONSERVER_ERROR_ALREADY_EXISTS:
    TRITONSERVER_errorcode_enum = 6;
#[doc = " The TRITONSERVER_Error error codes"]
pub type TRITONSERVER_errorcode_enum = ::std::os::raw::c_uint;
#[doc = " The TRITONSERVER_Error error codes"]
pub use self::TRITONSERVER_errorcode_enum as TRITONSERVER_Error_Code;
extern "C" {
    #[doc = " Create a new error object. The caller takes ownership of the\n TRITONSERVER_Error object and must call TRITONSERVER_ErrorDelete to\n release the object.\n\n \\param code The error code.\n \\param msg The error message.\n \\return A new TRITONSERVER_Error object."]
    pub fn TRITONSERVER_ErrorNew(
        code: TRITONSERVER_Error_Code,
        msg: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete an error object.\n\n \\param error The error object."]
    pub fn TRITONSERVER_ErrorDelete(error: *mut TRITONSERVER_Error);
}
extern "C" {
    #[doc = " Get the error code.\n\n \\param error The error object.\n \\return The error code."]
    pub fn TRITONSERVER_ErrorCode(error: *mut TRITONSERVER_Error) -> TRITONSERVER_Error_Code;
}
extern "C" {
    #[doc = " Get the string representation of an error code. The returned\n string is not owned by the caller and so should not be modified or\n freed. The lifetime of the returned string extends only as long as\n 'error' and must not be accessed once 'error' is deleted.\n\n \\param error The error object.\n \\return The string representation of the error code."]
    pub fn TRITONSERVER_ErrorCodeString(
        error: *mut TRITONSERVER_Error,
    ) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Get the error message. The returned string is not owned by the\n caller and so should not be modified or freed. The lifetime of the\n returned string extends only as long as 'error' and must not be\n accessed once 'error' is deleted.\n\n \\param error The error object.\n \\return The error message."]
    pub fn TRITONSERVER_ErrorMessage(
        error: *mut TRITONSERVER_Error,
    ) -> *const ::std::os::raw::c_char;
}
#[doc = " Type for allocation function that allocates a buffer to hold an\n output tensor.\n\n \\param allocator The allocator that is provided in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param tensor_name The name of the output tensor to allocate for.\n \\param byte_size The size of the buffer to allocate.\n \\param memory_type The type of memory that the caller prefers for\n the buffer allocation.\n \\param memory_type_id The ID of the memory that the caller prefers\n for the buffer allocation.\n \\param userp The user data pointer that is provided as\n 'response_allocator_userp' in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param buffer Returns a pointer to the allocated memory.\n \\param buffer_userp Returns a user-specified value to associate\n with the buffer, or nullptr if no user-specified value should be\n associated with the buffer. This value will be provided in the\n call to TRITONSERVER_ResponseAllocatorReleaseFn_t when the buffer\n is released and will also be returned by\n TRITONSERVER_InferenceResponseOutput.\n \\param actual_memory_type Returns the type of memory where the\n allocation resides. May be different than the type of memory\n requested by 'memory_type'.\n \\param actual_memory_type_id Returns the ID of the memory where\n the allocation resides. May be different than the ID of the memory\n requested by 'memory_type_id'.\n \\return a TRITONSERVER_Error object if a failure occurs while\n attempting an allocation. If an error is returned all other return\n values will be ignored."]
pub type TRITONSERVER_ResponseAllocatorAllocFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        allocator: *mut TRITONSERVER_ResponseAllocator,
        tensor_name: *const ::std::os::raw::c_char,
        byte_size: usize,
        memory_type: TRITONSERVER_MemoryType,
        memory_type_id: i64,
        userp: *mut ::std::os::raw::c_void,
        buffer: *mut *mut ::std::os::raw::c_void,
        buffer_userp: *mut *mut ::std::os::raw::c_void,
        actual_memory_type: *mut TRITONSERVER_MemoryType,
        actual_memory_type_id: *mut i64,
    ) -> *mut TRITONSERVER_Error,
>;
#[doc = " Type for allocation function that allocates a buffer to hold an\n output tensor with buffer attributes. The callback function must fill in the\n appropriate buffer attributes information related to this buffer. If set,\n this function is always called after TRITONSERVER_ResponseAllocatorAllocFn_t\n function.\n\n \\param allocator The allocator that is provided in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param tensor_name The name of the output tensor to allocate for.\n \\param buffer_attributes The buffer attributes associated with the buffer.\n \\param userp The user data pointer that is provided as\n 'response_allocator_userp' in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param buffer_userp Returns a user-specified value to associate\n with the buffer, or nullptr if no user-specified value should be\n associated with the buffer. This value will be provided in the\n call to TRITONSERVER_ResponseAllocatorReleaseFn_t when the buffer\n is released and will also be returned by\n TRITONSERVER_InferenceResponseOutput.\n \\return a TRITONSERVER_Error object if a failure occurs while\n attempting an allocation. If an error is returned all other return\n values will be ignored."]
pub type TRITONSERVER_ResponseAllocatorBufferAttributesFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        allocator: *mut TRITONSERVER_ResponseAllocator,
        tensor_name: *const ::std::os::raw::c_char,
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        userp: *mut ::std::os::raw::c_void,
        buffer_userp: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error,
>;
#[doc = " Type for function that is called to query the allocator's preferred memory\n type and memory type ID. As much as possible, the allocator should attempt\n to return the same memory_type and memory_type_id values that will be\n returned by the subsequent call to TRITONSERVER_ResponseAllocatorAllocFn_t.\n But the allocator is not required to do so.\n\n \\param allocator The allocator that is provided in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param userp The user data pointer that is provided as\n 'response_allocator_userp' in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param tensor_name The name of the output tensor. This is optional\n and it should be set to nullptr to indicate that the tensor name has\n not determined.\n \\param byte_size The expected size of the buffer. This is optional\n and it should be set to nullptr to indicate that the byte size has\n not determined.\n \\param memory_type Acts as both input and output. On input gives\n the memory type preferred by the caller. Returns memory type preferred\n by the allocator, taken account of the caller preferred type.\n \\param memory_type_id Acts as both input and output. On input gives\n the memory type ID preferred by the caller. Returns memory type ID preferred\n by the allocator, taken account of the caller preferred type ID.\n \\return a TRITONSERVER_Error object if a failure occurs."]
pub type TRITONSERVER_ResponseAllocatorQueryFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        allocator: *mut TRITONSERVER_ResponseAllocator,
        userp: *mut ::std::os::raw::c_void,
        tensor_name: *const ::std::os::raw::c_char,
        byte_size: *mut usize,
        memory_type: *mut TRITONSERVER_MemoryType,
        memory_type_id: *mut i64,
    ) -> *mut TRITONSERVER_Error,
>;
#[doc = " Type for function that is called when the server no longer holds\n any reference to a buffer allocated by\n TRITONSERVER_ResponseAllocatorAllocFn_t. In practice this function\n is typically called when the response object associated with the\n buffer is deleted by TRITONSERVER_InferenceResponseDelete.\n\n \\param allocator The allocator that is provided in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param buffer Pointer to the buffer to be freed.\n \\param buffer_userp The user-specified value associated\n with the buffer in TRITONSERVER_ResponseAllocatorAllocFn_t.\n \\param byte_size The size of the buffer.\n \\param memory_type The type of memory holding the buffer.\n \\param memory_type_id The ID of the memory holding the buffer.\n \\return a TRITONSERVER_Error object if a failure occurs while\n attempting the release. If an error is returned Triton will not\n attempt to release the buffer again."]
pub type TRITONSERVER_ResponseAllocatorReleaseFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        allocator: *mut TRITONSERVER_ResponseAllocator,
        buffer: *mut ::std::os::raw::c_void,
        buffer_userp: *mut ::std::os::raw::c_void,
        byte_size: usize,
        memory_type: TRITONSERVER_MemoryType,
        memory_type_id: i64,
    ) -> *mut TRITONSERVER_Error,
>;
#[doc = " Type for function that is called to indicate that subsequent\n allocation requests will refer to a new response.\n\n \\param allocator The allocator that is provided in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param userp The user data pointer that is provided as\n 'response_allocator_userp' in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\return a TRITONSERVER_Error object if a failure occurs."]
pub type TRITONSERVER_ResponseAllocatorStartFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        allocator: *mut TRITONSERVER_ResponseAllocator,
        userp: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error,
>;
extern "C" {
    #[doc = " Create a new response allocator object.\n\n The response allocator object is used by Triton to allocate\n buffers to hold the output tensors in inference responses. Most\n models generate a single response for each inference request\n (TRITONSERVER_TXN_ONE_TO_ONE). For these models the order of\n callbacks will be:\n\n   TRITONSERVER_ServerInferAsync called\n    - start_fn : optional (and typically not required)\n    - alloc_fn : called once for each output tensor in response\n   TRITONSERVER_InferenceResponseDelete called\n    - release_fn: called once for each output tensor in response\n\n For models that generate multiple responses for each inference\n request (TRITONSERVER_TXN_DECOUPLED), the start_fn callback can be\n used to determine sets of alloc_fn callbacks that belong to the\n same response:\n\n   TRITONSERVER_ServerInferAsync called\n    - start_fn\n    - alloc_fn : called once for each output tensor in response\n    - start_fn\n    - alloc_fn : called once for each output tensor in response\n      ...\n   For each response, TRITONSERVER_InferenceResponseDelete called\n    - release_fn: called once for each output tensor in the response\n\n In all cases the start_fn, alloc_fn and release_fn callback\n functions must be thread-safe. Typically making these functions\n thread-safe does not require explicit locking. The recommended way\n to implement these functions is to have each inference request\n provide a 'response_allocator_userp' object that is unique to that\n request with TRITONSERVER_InferenceRequestSetResponseCallback. The\n callback functions then operate only on this unique state. Locking\n is required only when the callback function needs to access state\n that is shared across inference requests (for example, a common\n allocation pool).\n\n \\param allocator Returns the new response allocator object.\n \\param alloc_fn The function to call to allocate buffers for result\n tensors.\n \\param release_fn The function to call when the server no longer\n holds a reference to an allocated buffer.\n \\param start_fn The function to call to indicate that the\n subsequent 'alloc_fn' calls are for a new response. This callback\n is optional (use nullptr to indicate that it should not be\n invoked).\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ResponseAllocatorNew(
        allocator: *mut *mut TRITONSERVER_ResponseAllocator,
        alloc_fn: TRITONSERVER_ResponseAllocatorAllocFn_t,
        release_fn: TRITONSERVER_ResponseAllocatorReleaseFn_t,
        start_fn: TRITONSERVER_ResponseAllocatorStartFn_t,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the buffer attributes function for a response allocator object.\n The function will be called after alloc_fn to set the buffer attributes\n associated with the output buffer.\n\n The thread-safy requirement for buffer_attributes_fn is the same as other\n allocator callbacks.\n\n \\param allocator The response allocator object.\n \\param buffer_attributes_fn The function to call to get the buffer\n attributes information for an allocated buffer.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ResponseAllocatorSetBufferAttributesFunction(
        allocator: *mut TRITONSERVER_ResponseAllocator,
        buffer_attributes_fn: TRITONSERVER_ResponseAllocatorBufferAttributesFn_t,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the query function to a response allocator object. Usually the\n function will be called before alloc_fn to understand what is the\n allocator's preferred memory type and memory type ID at the current\n situation to make different execution decision.\n\n The thread-safy requirement for query_fn is the same as other allocator\n callbacks.\n\n \\param allocator The response allocator object.\n \\param query_fn The function to call to query allocator's preferred memory\n type and memory type ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ResponseAllocatorSetQueryFunction(
        allocator: *mut TRITONSERVER_ResponseAllocator,
        query_fn: TRITONSERVER_ResponseAllocatorQueryFn_t,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a response allocator.\n\n \\param allocator The response allocator object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ResponseAllocatorDelete(
        allocator: *mut TRITONSERVER_ResponseAllocator,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Create a new message object from serialized JSON string.\n\n \\param message The message object.\n \\param base The base of the serialized JSON.\n \\param byte_size The size, in bytes, of the serialized message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MessageNewFromSerializedJson(
        message: *mut *mut TRITONSERVER_Message,
        base: *const ::std::os::raw::c_char,
        byte_size: usize,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a message object.\n\n \\param message The message object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MessageDelete(
        message: *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the base and size of the buffer containing the serialized\n message in JSON format. The buffer is owned by the\n TRITONSERVER_Message object and should not be modified or freed by\n the caller. The lifetime of the buffer extends only as long as\n 'message' and must not be accessed once 'message' is deleted.\n\n \\param message The message object.\n \\param base Returns the base of the serialized message.\n \\param byte_size Returns the size, in bytes, of the serialized\n message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MessageSerializeToJson(
        message: *mut TRITONSERVER_Message,
        base: *mut *const ::std::os::raw::c_char,
        byte_size: *mut usize,
    ) -> *mut TRITONSERVER_Error;
}
pub const tritonserver_metricformat_enum_TRITONSERVER_METRIC_PROMETHEUS:
    tritonserver_metricformat_enum = 0;
#[doc = " Metric format types"]
pub type tritonserver_metricformat_enum = ::std::os::raw::c_uint;
#[doc = " Metric format types"]
pub use self::tritonserver_metricformat_enum as TRITONSERVER_MetricFormat;
extern "C" {
    #[doc = " Delete a metrics object.\n\n \\param metrics The metrics object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricsDelete(
        metrics: *mut TRITONSERVER_Metrics,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get a buffer containing the metrics in the specified format. For\n each format the buffer contains the following:\n\n   TRITONSERVER_METRIC_PROMETHEUS: 'base' points to a single multiline\n   string (char*) that gives a text representation of the metrics in\n   prometheus format. 'byte_size' returns the length of the string\n   in bytes.\n\n The buffer is owned by the 'metrics' object and should not be\n modified or freed by the caller. The lifetime of the buffer\n extends only as long as 'metrics' and must not be accessed once\n 'metrics' is deleted.\n\n \\param metrics The metrics object.\n \\param format The format to use for the returned metrics.\n \\param base Returns a pointer to the base of the formatted\n metrics, as described above.\n \\param byte_size Returns the size, in bytes, of the formatted\n metrics.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricsFormatted(
        metrics: *mut TRITONSERVER_Metrics,
        format: TRITONSERVER_MetricFormat,
        base: *mut *const ::std::os::raw::c_char,
        byte_size: *mut usize,
    ) -> *mut TRITONSERVER_Error;
}
#[doc = " Tracing disabled. No trace activities are reported."]
pub const tritonserver_tracelevel_enum_TRITONSERVER_TRACE_LEVEL_DISABLED:
    tritonserver_tracelevel_enum = 0;
#[doc = " Deprecated. Use TRITONSERVER_TRACE_LEVEL_TIMESTAMPS."]
pub const tritonserver_tracelevel_enum_TRITONSERVER_TRACE_LEVEL_MIN: tritonserver_tracelevel_enum =
    1;
#[doc = " Deprecated. Use TRITONSERVER_TRACE_LEVEL_TIMESTAMPS."]
pub const tritonserver_tracelevel_enum_TRITONSERVER_TRACE_LEVEL_MAX: tritonserver_tracelevel_enum =
    2;
#[doc = " Record timestamps for the inference request."]
pub const tritonserver_tracelevel_enum_TRITONSERVER_TRACE_LEVEL_TIMESTAMPS:
    tritonserver_tracelevel_enum = 4;
#[doc = " Record input and output tensor values for the inference request."]
pub const tritonserver_tracelevel_enum_TRITONSERVER_TRACE_LEVEL_TENSORS:
    tritonserver_tracelevel_enum = 8;
#[doc = " Trace levels. The trace level controls the type of trace\n activities that are reported for an inference request.\n\n Trace level values are power-of-2 and can be combined to trace\n multiple types of activities. For example, use\n (TRITONSERVER_TRACE_LEVEL_TIMESTAMPS |\n TRITONSERVER_TRACE_LEVEL_TENSORS) to trace both timestamps and\n tensors for an inference request.\n\n TRITONSERVER_TRACE_LEVEL_MIN and TRITONSERVER_TRACE_LEVEL_MAX are\n deprecated and should not be used."]
pub type tritonserver_tracelevel_enum = ::std::os::raw::c_uint;
#[doc = " Trace levels. The trace level controls the type of trace\n activities that are reported for an inference request.\n\n Trace level values are power-of-2 and can be combined to trace\n multiple types of activities. For example, use\n (TRITONSERVER_TRACE_LEVEL_TIMESTAMPS |\n TRITONSERVER_TRACE_LEVEL_TENSORS) to trace both timestamps and\n tensors for an inference request.\n\n TRITONSERVER_TRACE_LEVEL_MIN and TRITONSERVER_TRACE_LEVEL_MAX are\n deprecated and should not be used."]
pub use self::tritonserver_tracelevel_enum as TRITONSERVER_InferenceTraceLevel;
extern "C" {
    #[doc = " Get the string representation of a trace level. The returned\n string is not owned by the caller and so should not be modified or\n freed.\n\n \\param level The trace level.\n \\return The string representation of the trace level."]
    pub fn TRITONSERVER_InferenceTraceLevelString(
        level: TRITONSERVER_InferenceTraceLevel,
    ) -> *const ::std::os::raw::c_char;
}
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_REQUEST_START:
    tritonserver_traceactivity_enum = 0;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_QUEUE_START:
    tritonserver_traceactivity_enum = 1;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_COMPUTE_START:
    tritonserver_traceactivity_enum = 2;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_COMPUTE_INPUT_END:
    tritonserver_traceactivity_enum = 3;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_COMPUTE_OUTPUT_START:
    tritonserver_traceactivity_enum = 4;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_COMPUTE_END:
    tritonserver_traceactivity_enum = 5;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_REQUEST_END:
    tritonserver_traceactivity_enum = 6;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_TENSOR_QUEUE_INPUT:
    tritonserver_traceactivity_enum = 7;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_TENSOR_BACKEND_INPUT:
    tritonserver_traceactivity_enum = 8;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_TENSOR_BACKEND_OUTPUT:
    tritonserver_traceactivity_enum = 9;
#[doc = " Trace activities"]
pub type tritonserver_traceactivity_enum = ::std::os::raw::c_uint;
#[doc = " Trace activities"]
pub use self::tritonserver_traceactivity_enum as TRITONSERVER_InferenceTraceActivity;
extern "C" {
    #[doc = " Get the string representation of a trace activity. The returned\n string is not owned by the caller and so should not be modified or\n freed.\n\n \\param activity The trace activity.\n \\return The string representation of the trace activity."]
    pub fn TRITONSERVER_InferenceTraceActivityString(
        activity: TRITONSERVER_InferenceTraceActivity,
    ) -> *const ::std::os::raw::c_char;
}
#[doc = " Type for trace timeline activity callback function. This callback function\n is used to report activity occurring for a trace. This function\n does not take ownership of 'trace' and so any information needed\n from that object must be copied before returning. The 'userp' data\n is the same as what is supplied in the call to\n TRITONSERVER_InferenceTraceNew."]
pub type TRITONSERVER_InferenceTraceActivityFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        trace: *mut TRITONSERVER_InferenceTrace,
        activity: TRITONSERVER_InferenceTraceActivity,
        timestamp_ns: u64,
        userp: *mut ::std::os::raw::c_void,
    ),
>;
#[doc = " Type for trace tensor activity callback function. This callback function\n is used to report tensor activity occurring for a trace. This function\n does not take ownership of 'trace' and so any information needed\n from that object must be copied before returning. The 'userp' data\n is the same as what is supplied in the call to\n TRITONSERVER_InferenceTraceTensorNew."]
pub type TRITONSERVER_InferenceTraceTensorActivityFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        trace: *mut TRITONSERVER_InferenceTrace,
        activity: TRITONSERVER_InferenceTraceActivity,
        name: *const ::std::os::raw::c_char,
        datatype: TRITONSERVER_DataType,
        base: *const ::std::os::raw::c_void,
        byte_size: usize,
        shape: *const i64,
        dim_count: u64,
        memory_type: TRITONSERVER_MemoryType,
        memory_type_id: i64,
        userp: *mut ::std::os::raw::c_void,
    ),
>;
#[doc = " Type for trace release callback function. This callback function\n is called when all activity for the trace has completed. The\n callback function takes ownership of the\n TRITONSERVER_InferenceTrace object. The 'userp' data is the same\n as what is supplied in the call to TRITONSERVER_InferenceTraceNew."]
pub type TRITONSERVER_InferenceTraceReleaseFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        trace: *mut TRITONSERVER_InferenceTrace,
        userp: *mut ::std::os::raw::c_void,
    ),
>;
extern "C" {
    #[doc = " Create a new inference trace object. The caller takes ownership of\n the TRITONSERVER_InferenceTrace object and must call\n TRITONSERVER_InferenceTraceDelete to release the object.\n\n The activity callback function will be called to report activity\n for 'trace' as well as for any child traces that are spawned by\n 'trace', and so the activity callback must check the trace object\n to determine specifically what activity is being reported.\n\n The release callback is called for both 'trace' and for any child\n traces spawned by 'trace'.\n\n \\param trace Returns the new inference trace object.\n \\param level The tracing level.\n \\param parent_id The parent trace id for this trace. A value of 0\n indicates that there is not parent trace.\n \\param activity_fn The callback function where activity for the\n trace is reported.\n \\param release_fn The callback function called when all activity\n is complete for the trace.\n \\param trace_userp User-provided pointer that is delivered to\n the activity and release callback functions.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceTraceNew(
        trace: *mut *mut TRITONSERVER_InferenceTrace,
        level: TRITONSERVER_InferenceTraceLevel,
        parent_id: u64,
        activity_fn: TRITONSERVER_InferenceTraceActivityFn_t,
        release_fn: TRITONSERVER_InferenceTraceReleaseFn_t,
        trace_userp: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Create a new inference trace object. The caller takes ownership of\n the TRITONSERVER_InferenceTrace object and must call\n TRITONSERVER_InferenceTraceDelete to release the object.\n\n The timeline and tensor activity callback function will be called to report\n activity for 'trace' as well as for any child traces that are spawned by\n 'trace', and so the activity callback must check the trace object\n to determine specifically what activity is being reported.\n\n The release callback is called for both 'trace' and for any child\n traces spawned by 'trace'.\n\n \\param trace Returns the new inference trace object.\n \\param level The tracing level.\n \\param parent_id The parent trace id for this trace. A value of 0\n indicates that there is not parent trace.\n \\param activity_fn The callback function where timeline activity for the\n trace is reported.\n \\param tensor_activity_fn The callback function where tensor activity for\n the trace is reported.\n \\param release_fn The callback function called when all activity\n is complete for the trace.\n \\param trace_userp User-provided pointer that is delivered to\n the activity and release callback functions.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceTraceTensorNew(
        trace: *mut *mut TRITONSERVER_InferenceTrace,
        level: TRITONSERVER_InferenceTraceLevel,
        parent_id: u64,
        activity_fn: TRITONSERVER_InferenceTraceActivityFn_t,
        tensor_activity_fn: TRITONSERVER_InferenceTraceTensorActivityFn_t,
        release_fn: TRITONSERVER_InferenceTraceReleaseFn_t,
        trace_userp: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a trace object.\n\n \\param trace The trace object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceTraceDelete(
        trace: *mut TRITONSERVER_InferenceTrace,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the id associated with a trace. Every trace is assigned an id\n that is unique across all traces created for a Triton server.\n\n \\param trace The trace.\n \\param id Returns the id associated with the trace.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceTraceId(
        trace: *mut TRITONSERVER_InferenceTrace,
        id: *mut u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the parent id associated with a trace. The parent id indicates\n a parent-child relationship between two traces. A parent id value\n of 0 indicates that there is no parent trace.\n\n \\param trace The trace.\n \\param id Returns the parent id associated with the trace.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceTraceParentId(
        trace: *mut TRITONSERVER_InferenceTrace,
        parent_id: *mut u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the name of the model associated with a trace. The caller does\n not own the returned string and must not modify or delete it. The\n lifetime of the returned string extends only as long as 'trace'.\n\n \\param trace The trace.\n \\param model_name Returns the name of the model associated with\n the trace.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceTraceModelName(
        trace: *mut TRITONSERVER_InferenceTrace,
        model_name: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the version of the model associated with a trace.\n\n \\param trace The trace.\n \\param model_version Returns the version of the model associated\n with the trace.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceTraceModelVersion(
        trace: *mut TRITONSERVER_InferenceTrace,
        model_version: *mut i64,
    ) -> *mut TRITONSERVER_Error;
}
pub const tritonserver_requestflag_enum_TRITONSERVER_REQUEST_FLAG_SEQUENCE_START:
    tritonserver_requestflag_enum = 1;
pub const tritonserver_requestflag_enum_TRITONSERVER_REQUEST_FLAG_SEQUENCE_END:
    tritonserver_requestflag_enum = 2;
#[doc = " Inference request flags. The enum values must be power-of-2 values."]
pub type tritonserver_requestflag_enum = ::std::os::raw::c_uint;
#[doc = " Inference request flags. The enum values must be power-of-2 values."]
pub use self::tritonserver_requestflag_enum as TRITONSERVER_RequestFlag;
pub const tritonserver_requestreleaseflag_enum_TRITONSERVER_REQUEST_RELEASE_ALL:
    tritonserver_requestreleaseflag_enum = 1;
#[doc = " Inference request release flags. The enum values must be\n power-of-2 values."]
pub type tritonserver_requestreleaseflag_enum = ::std::os::raw::c_uint;
#[doc = " Inference request release flags. The enum values must be\n power-of-2 values."]
pub use self::tritonserver_requestreleaseflag_enum as TRITONSERVER_RequestReleaseFlag;
pub const tritonserver_responsecompleteflag_enum_TRITONSERVER_RESPONSE_COMPLETE_FINAL:
    tritonserver_responsecompleteflag_enum = 1;
#[doc = " Inference response complete flags. The enum values must be\n power-of-2 values."]
pub type tritonserver_responsecompleteflag_enum = ::std::os::raw::c_uint;
#[doc = " Inference response complete flags. The enum values must be\n power-of-2 values."]
pub use self::tritonserver_responsecompleteflag_enum as TRITONSERVER_ResponseCompleteFlag;
#[doc = " Type for inference request release callback function. The callback\n indicates what type of release is being performed on the request\n and for some of these the callback function takes ownership of the\n TRITONSERVER_InferenceRequest object. The 'userp' data is the data\n provided as 'request_release_userp' in the call to\n TRITONSERVER_InferenceRequestSetReleaseCallback.\n\n One or more flags will be specified when the callback is invoked,\n and the callback must take the following actions:\n\n   - TRITONSERVER_REQUEST_RELEASE_ALL: The entire inference request\n     is being released and ownership is passed to the callback\n     function. Triton will not longer access the 'request' object\n     itself nor any input tensor data associated with the\n     request. The callback should free or otherwise manage the\n     'request' object and all associated tensor data.\n\n Note that currently TRITONSERVER_REQUEST_RELEASE_ALL should always\n be set when the callback is invoked but in the future that may\n change, so the callback should explicitly check for the flag\n before taking ownership of the request object.\n"]
pub type TRITONSERVER_InferenceRequestReleaseFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        request: *mut TRITONSERVER_InferenceRequest,
        flags: u32,
        userp: *mut ::std::os::raw::c_void,
    ),
>;
#[doc = " Type for callback function indicating that an inference response\n has completed. The callback function takes ownership of the\n TRITONSERVER_InferenceResponse object. The 'userp' data is the\n data provided as 'response_userp' in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n\n One or more flags may be specified when the callback is invoked:\n\n   - TRITONSERVER_RESPONSE_COMPLETE_FINAL: Indicates that no more\n     responses will be generated for a given request (more\n     specifically, that no more responses will be generated for the\n     inference request that set this callback and 'userp'). When\n     this flag is set 'response' may be a response object or may be\n     nullptr. If 'response' is not nullptr, then 'response' is the\n     last response that Triton will produce for the request. If\n     'response' is nullptr then Triton is indicating that no more\n     responses will be produced for the request."]
pub type TRITONSERVER_InferenceResponseCompleteFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        response: *mut TRITONSERVER_InferenceResponse,
        flags: u32,
        userp: *mut ::std::os::raw::c_void,
    ),
>;
extern "C" {
    #[doc = " Create a new inference request object.\n\n \\param inference_request Returns the new request object.\n \\param server the inference server object.\n \\param model_name The name of the model to use for the request.\n \\param model_version The version of the model to use for the\n request. If -1 then the server will choose a version based on the\n model's policy.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestNew(
        inference_request: *mut *mut TRITONSERVER_InferenceRequest,
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        model_version: i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete an inference request object.\n\n \\param inference_request The request object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestDelete(
        inference_request: *mut TRITONSERVER_InferenceRequest,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the ID for a request. The returned ID is owned by\n 'inference_request' and must not be modified or freed by the\n caller.\n\n \\param inference_request The request object.\n \\param id Returns the ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestId(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        id: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the ID for a request.\n\n \\param inference_request The request object.\n \\param id The ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetId(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        id: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the flag(s) associated with a request. On return 'flags' holds\n a bitwise-or of all flag values, see TRITONSERVER_RequestFlag for\n available flags.\n\n \\param inference_request The request object.\n \\param flags Returns the flags.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestFlags(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        flags: *mut u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the flag(s) associated with a request. 'flags' should hold a\n bitwise-or of all flag values, see TRITONSERVER_RequestFlag for\n available flags.\n\n \\param inference_request The request object.\n \\param flags The flags.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetFlags(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        flags: u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the correlation ID of the inference request as an unsigned integer.\n Default is 0, which indicates that the request has no correlation ID.\n If the correlation id associated with the inference request is a string,\n this function will return a failure. The correlation ID is used\n to indicate two or more inference request are related to each other.\n How this relationship is handled by the inference server is determined by\n the model's scheduling policy.\n\n \\param inference_request The request object.\n \\param correlation_id Returns the correlation ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestCorrelationId(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        correlation_id: *mut u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the correlation ID of the inference request as a string.\n Default is empty \"\", which indicates that the request has no correlation ID.\n If the correlation id associated with the inference request is an unsigned\n integer, then this function will return a failure. The correlation ID\n is used to indicate two or more inference request are related to each other.\n How this relationship is handled by the inference server is determined by\n the model's scheduling policy.\n\n \\param inference_request The request object.\n \\param correlation_id Returns the correlation ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestCorrelationIdString(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        correlation_id: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the correlation ID of the inference request to be an unsigned integer.\n Default is 0, which indicates that the request has no correlation ID.\n The correlation ID is used to indicate two or more inference request\n are related to each other. How this relationship is handled by the\n inference server is determined by the model's scheduling policy.\n\n \\param inference_request The request object.\n \\param correlation_id The correlation ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetCorrelationId(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        correlation_id: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the correlation ID of the inference request to be a string.\n The correlation ID is used to indicate two or more inference\n request are related to each other. How this relationship is\n handled by the inference server is determined by the model's\n scheduling policy.\n\n \\param inference_request The request object.\n \\param correlation_id The correlation ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetCorrelationIdString(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        correlation_id: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the priority for a request. The default is 0 indicating that\n the request does not specify a priority and so will use the\n model's default priority.\n\n \\param inference_request The request object.\n \\param priority Returns the priority level.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestPriority(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        priority: *mut u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the priority for a request. The default is 0 indicating that\n the request does not specify a priority and so will use the\n model's default priority.\n\n \\param inference_request The request object.\n \\param priority The priority level.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetPriority(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        priority: u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the timeout for a request, in microseconds. The default is 0\n which indicates that the request has no timeout.\n\n \\param inference_request The request object.\n \\param timeout_us Returns the timeout, in microseconds.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestTimeoutMicroseconds(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        timeout_us: *mut u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the timeout for a request, in microseconds. The default is 0\n which indicates that the request has no timeout.\n\n \\param inference_request The request object.\n \\param timeout_us The timeout, in microseconds.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetTimeoutMicroseconds(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        timeout_us: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Add an input to a request.\n\n \\param inference_request The request object.\n \\param name The name of the input.\n \\param datatype The type of the input. Valid type names are BOOL,\n UINT8, UINT16, UINT32, UINT64, INT8, INT16, INT32, INT64, FP16,\n FP32, FP64, and BYTES.\n \\param shape The shape of the input.\n \\param dim_count The number of dimensions of 'shape'.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestAddInput(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
        datatype: TRITONSERVER_DataType,
        shape: *const i64,
        dim_count: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Add a raw input to a request. The name recognized by the model, data type\n and shape of the input will be deduced from model configuration.\n This function must be called at most once on request with no other input to\n ensure the deduction is accurate.\n\n \\param inference_request The request object.\n \\param name The name of the input. This name is only used as a reference\n of the raw input in other Tritonserver APIs. It doesn't assoicate with the\n name used in the model.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestAddRawInput(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Remove an input from a request.\n\n \\param inference_request The request object.\n \\param name The name of the input.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestRemoveInput(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Remove all inputs from a request.\n\n \\param inference_request The request object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestRemoveAllInputs(
        inference_request: *mut TRITONSERVER_InferenceRequest,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Assign a buffer of data to an input. The buffer will be appended\n to any existing buffers for that input. The 'inference_request'\n object takes ownership of the buffer and so the caller should not\n modify or free the buffer until that ownership is released by\n 'inference_request' being deleted or by the input being removed\n from 'inference_request'.\n\n \\param inference_request The request object.\n \\param name The name of the input.\n \\param base The base address of the input data.\n \\param byte_size The size, in bytes, of the input data.\n \\param memory_type The memory type of the input data.\n \\param memory_type_id The memory type id of the input data.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestAppendInputData(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
        base: *const ::std::os::raw::c_void,
        byte_size: usize,
        memory_type: TRITONSERVER_MemoryType,
        memory_type_id: i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Assign a buffer of data to an input for execution on all model instances\n with the specified host policy. The buffer will be appended to any existing\n buffers for that input on all devices with this host policy. The\n 'inference_request' object takes ownership of the buffer and so the caller\n should not modify or free the buffer until that ownership is released by\n 'inference_request' being deleted or by the input being removed from\n 'inference_request'. If the execution is scheduled on a device that does not\n have a input buffer specified using this function, then the input buffer\n specified with TRITONSERVER_InferenceRequestAppendInputData will be used so\n a non-host policy specific version of data must be added using that API.\n \\param inference_request The request object.\n \\param name The name of the input.\n \\param base The base address of the input data.\n \\param byte_size The size, in bytes, of the input data.\n \\param memory_type The memory type of the input data.\n \\param memory_type_id The memory type id of the input data.\n \\param host_policy_name All model instances executing with this host_policy\n will use this input buffer for execution.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestAppendInputDataWithHostPolicy(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
        base: *const ::std::os::raw::c_void,
        byte_size: usize,
        memory_type: TRITONSERVER_MemoryType,
        memory_type_id: i64,
        host_policy_name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Assign a buffer of data to an input. The buffer will be appended\n to any existing buffers for that input. The 'inference_request'\n object takes ownership of the buffer and so the caller should not\n modify or free the buffer until that ownership is released by\n 'inference_request' being deleted or by the input being removed\n from 'inference_request'.\n\n \\param inference_request The request object.\n \\param name The name of the input.\n \\param base The base address of the input data.\n \\param buffer_attributes The buffer attrubutes of the input.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestAppendInputDataWithBufferAttributes(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
        base: *const ::std::os::raw::c_void,
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Clear all input data from an input, releasing ownership of the\n buffer(s) that were appended to the input with\n TRITONSERVER_InferenceRequestAppendInputData or\n TRITONSERVER_InferenceRequestAppendInputDataWithHostPolicy\n \\param inference_request The request object.\n \\param name The name of the input."]
    pub fn TRITONSERVER_InferenceRequestRemoveAllInputData(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Add an output request to an inference request.\n\n \\param inference_request The request object.\n \\param name The name of the output.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestAddRequestedOutput(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Remove an output request from an inference request.\n\n \\param inference_request The request object.\n \\param name The name of the output.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestRemoveRequestedOutput(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Remove all output requests from an inference request.\n\n \\param inference_request The request object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestRemoveAllRequestedOutputs(
        inference_request: *mut TRITONSERVER_InferenceRequest,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the release callback for an inference request. The release\n callback is called by Triton to return ownership of the request\n object.\n\n \\param inference_request The request object.\n \\param request_release_fn The function called to return ownership\n of the 'inference_request' object.\n \\param request_release_userp User-provided pointer that is\n delivered to the 'request_release_fn' callback.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetReleaseCallback(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        request_release_fn: TRITONSERVER_InferenceRequestReleaseFn_t,
        request_release_userp: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the allocator and response callback for an inference\n request. The allocator is used to allocate buffers for any output\n tensors included in responses that are produced for this\n request. The response callback is called to return response\n objects representing responses produced for this request.\n\n \\param inference_request The request object.\n \\param response_allocator The TRITONSERVER_ResponseAllocator to use\n to allocate buffers to hold inference results.\n \\param response_allocator_userp User-provided pointer that is\n delivered to the response allocator's start and allocation functions.\n \\param response_fn The function called to deliver an inference\n response for this request.\n \\param response_userp User-provided pointer that is delivered to\n the 'response_fn' callback.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetResponseCallback(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        response_allocator: *mut TRITONSERVER_ResponseAllocator,
        response_allocator_userp: *mut ::std::os::raw::c_void,
        response_fn: TRITONSERVER_InferenceResponseCompleteFn_t,
        response_userp: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete an inference response object.\n\n \\param inference_response The response object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseDelete(
        inference_response: *mut TRITONSERVER_InferenceResponse,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Return the error status of an inference response. Return a\n TRITONSERVER_Error object on failure, return nullptr on success.\n The returned error object is owned by 'inference_response' and so\n should not be deleted by the caller.\n\n \\param inference_response The response object.\n \\return a TRITONSERVER_Error indicating the success or failure\n status of the response."]
    pub fn TRITONSERVER_InferenceResponseError(
        inference_response: *mut TRITONSERVER_InferenceResponse,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get model used to produce a response. The caller does not own the\n returned model name value and must not modify or delete it. The\n lifetime of all returned values extends until 'inference_response'\n is deleted.\n\n \\param inference_response The response object.\n \\param model_name Returns the name of the model.\n \\param model_version Returns the version of the model.\n this response.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseModel(
        inference_response: *mut TRITONSERVER_InferenceResponse,
        model_name: *mut *const ::std::os::raw::c_char,
        model_version: *mut i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the ID of the request corresponding to a response. The caller\n does not own the returned ID and must not modify or delete it. The\n lifetime of all returned values extends until 'inference_response'\n is deleted.\n\n \\param inference_response The response object.\n \\param request_id Returns the ID of the request corresponding to\n this response.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseId(
        inference_response: *mut TRITONSERVER_InferenceResponse,
        request_id: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the number of parameters available in the response.\n\n \\param inference_response The response object.\n \\param count Returns the number of parameters.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseParameterCount(
        inference_response: *mut TRITONSERVER_InferenceResponse,
        count: *mut u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get all information about a parameter. The caller does not own any\n of the returned values and must not modify or delete them. The\n lifetime of all returned values extends until 'inference_response'\n is deleted.\n\n The 'vvalue' returns a void* pointer that must be cast\n appropriately based on 'type'. For example:\n\n   void* vvalue;\n   TRITONSERVER_ParameterType type;\n   TRITONSERVER_InferenceResponseParameter(\n                     response, index, &name, &type, &vvalue);\n   switch (type) {\n     case TRITONSERVER_PARAMETER_BOOL:\n       bool value = *(reinterpret_cast<bool*>(vvalue));\n       ...\n     case TRITONSERVER_PARAMETER_INT:\n       int64_t value = *(reinterpret_cast<int64_t*>(vvalue));\n       ...\n     case TRITONSERVER_PARAMETER_STRING:\n       const char* value = reinterpret_cast<const char*>(vvalue);\n       ...\n\n \\param inference_response The response object.\n \\param index The index of the parameter, must be 0 <= index <\n count, where 'count' is the value returned by\n TRITONSERVER_InferenceResponseParameterCount.\n \\param name Returns the name of the parameter.\n \\param type Returns the type of the parameter.\n \\param vvalue Returns a pointer to the parameter value.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseParameter(
        inference_response: *mut TRITONSERVER_InferenceResponse,
        index: u32,
        name: *mut *const ::std::os::raw::c_char,
        type_: *mut TRITONSERVER_ParameterType,
        vvalue: *mut *const ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the number of outputs available in the response.\n\n \\param inference_response The response object.\n \\param count Returns the number of output tensors.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseOutputCount(
        inference_response: *mut TRITONSERVER_InferenceResponse,
        count: *mut u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get all information about an output tensor.  The tensor data is\n returned as the base pointer to the data and the size, in bytes,\n of the data. The caller does not own any of the returned values\n and must not modify or delete them. The lifetime of all returned\n values extends until 'inference_response' is deleted.\n\n \\param inference_response The response object.\n \\param index The index of the output tensor, must be 0 <= index <\n count, where 'count' is the value returned by\n TRITONSERVER_InferenceResponseOutputCount.\n \\param name Returns the name of the output.\n \\param datatype Returns the type of the output.\n \\param shape Returns the shape of the output.\n \\param dim_count Returns the number of dimensions of the returned\n shape.\n \\param base Returns the tensor data for the output.\n \\param byte_size Returns the size, in bytes, of the data.\n \\param memory_type Returns the memory type of the data.\n \\param memory_type_id Returns the memory type id of the data.\n \\param userp The user-specified value associated with the buffer\n in TRITONSERVER_ResponseAllocatorAllocFn_t.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseOutput(
        inference_response: *mut TRITONSERVER_InferenceResponse,
        index: u32,
        name: *mut *const ::std::os::raw::c_char,
        datatype: *mut TRITONSERVER_DataType,
        shape: *mut *const i64,
        dim_count: *mut u64,
        base: *mut *const ::std::os::raw::c_void,
        byte_size: *mut usize,
        memory_type: *mut TRITONSERVER_MemoryType,
        memory_type_id: *mut i64,
        userp: *mut *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get a classification label associated with an output for a given\n index.  The caller does not own the returned label and must not\n modify or delete it. The lifetime of all returned label extends\n until 'inference_response' is deleted.\n\n \\param inference_response The response object.\n \\param index The index of the output tensor, must be 0 <= index <\n count, where 'count' is the value returned by\n TRITONSERVER_InferenceResponseOutputCount.\n \\param class_index The index of the class.\n \\param name Returns the label corresponding to 'class_index' or\n nullptr if no label.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseOutputClassificationLabel(
        inference_response: *mut TRITONSERVER_InferenceResponse,
        index: u32,
        class_index: usize,
        label: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Create a new buffer attributes object. The caller takes ownership of\n the TRITONSERVER_BufferAttributes object and must call\n TRITONSERVER_BufferAttributesDelete to release the object.\n\n \\param buffer_attributes Returns the new buffer attributes object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesNew(
        buffer_attributes: *mut *mut TRITONSERVER_BufferAttributes,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a buffer attributes object.\n\n \\param buffer_attributes The buffer_attributes object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesDelete(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the memory type id field of the buffer attributes.\n\n \\param buffer_attributes The buffer attributes object.\n \\param memory_type_id Memory type id to assign to the buffer attributes\n object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesSetMemoryTypeId(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        memory_type_id: i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the memory type field of the buffer attributes.\n\n \\param buffer_attributes The buffer attributes object.\n \\param memory_type Memory type to assign to the buffer attributes object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesSetMemoryType(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        memory_type: TRITONSERVER_MemoryType,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the CudaIpcHandle field of the buffer attributes.\n\n \\param buffer_attributes The buffer attributes object.\n \\param cuda_ipc_handle The CudaIpcHandle to assign to the buffer attributes\n object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesSetCudaIpcHandle(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        cuda_ipc_handle: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the byte size field of the buffer attributes.\n\n \\param buffer_attributes The buffer attributes object.\n \\param byte_size Byte size to assign to the buffer attributes object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesSetByteSize(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        byte_size: usize,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the memory type id field of the buffer attributes.\n\n \\param buffer_attributes The buffer attributes object.\n \\param memory_type_id Returns the memory type id associated with the buffer\n attributes object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesMemoryTypeId(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        memory_type_id: *mut i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the memory type field of the buffer attributes.\n\n \\param buffer_attributes The buffer attributes object.\n \\param memory_type Returns the memory type associated with the buffer\n attributes object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesMemoryType(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        memory_type: *mut TRITONSERVER_MemoryType,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the CudaIpcHandle field of the buffer attributes object.\n\n \\param buffer_attributes The buffer attributes object.\n \\param cuda_ipc_handle Returns the memory type associated with the buffer\n attributes object. If the cudaIpcHandle does not exist for the buffer,\n nullptr will be returned.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesCudaIpcHandle(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        cuda_ipc_handle: *mut *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the byte size field of the buffer attributes.\n\n \\param buffer_attributes The buffer attributes object.\n \\param byte_size Returns the byte size associated with the buffer attributes\n object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesByteSize(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        byte_size: *mut usize,
    ) -> *mut TRITONSERVER_Error;
}
pub const tritonserver_modelcontrolmode_enum_TRITONSERVER_MODEL_CONTROL_NONE:
    tritonserver_modelcontrolmode_enum = 0;
pub const tritonserver_modelcontrolmode_enum_TRITONSERVER_MODEL_CONTROL_POLL:
    tritonserver_modelcontrolmode_enum = 1;
pub const tritonserver_modelcontrolmode_enum_TRITONSERVER_MODEL_CONTROL_EXPLICIT:
    tritonserver_modelcontrolmode_enum = 2;
#[doc = " Model control modes"]
pub type tritonserver_modelcontrolmode_enum = ::std::os::raw::c_uint;
#[doc = " Model control modes"]
pub use self::tritonserver_modelcontrolmode_enum as TRITONSERVER_ModelControlMode;
pub const tritonserver_ratelimitmode_enum_TRITONSERVER_RATE_LIMIT_OFF:
    tritonserver_ratelimitmode_enum = 0;
pub const tritonserver_ratelimitmode_enum_TRITONSERVER_RATE_LIMIT_EXEC_COUNT:
    tritonserver_ratelimitmode_enum = 1;
#[doc = " Rate limit modes"]
pub type tritonserver_ratelimitmode_enum = ::std::os::raw::c_uint;
#[doc = " Rate limit modes"]
pub use self::tritonserver_ratelimitmode_enum as TRITONSERVER_RateLimitMode;
extern "C" {
    #[doc = " Create a new server options object. The caller takes ownership of\n the TRITONSERVER_ServerOptions object and must call\n TRITONSERVER_ServerOptionsDelete to release the object.\n\n \\param options Returns the new server options object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsNew(
        options: *mut *mut TRITONSERVER_ServerOptions,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a server options object.\n\n \\param options The server options object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsDelete(
        options: *mut TRITONSERVER_ServerOptions,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the textual ID for the server in a server options. The ID is a\n name that identifies the server.\n\n \\param options The server options object.\n \\param server_id The server identifier.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetServerId(
        options: *mut TRITONSERVER_ServerOptions,
        server_id: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the model repository path in a server options. The path must be\n the full absolute path to the model repository. This function can be called\n multiple times with different paths to set multiple model repositories.\n Note that if a model is not unique across all model repositories\n at any time, the model will not be available.\n\n \\param options The server options object.\n \\param model_repository_path The full path to the model repository.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetModelRepositoryPath(
        options: *mut TRITONSERVER_ServerOptions,
        model_repository_path: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the model control mode in a server options. For each mode the models\n will be managed as the following:\n\n   TRITONSERVER_MODEL_CONTROL_NONE: the models in model repository will be\n   loaded on startup. After startup any changes to the model repository will\n   be ignored. Calling TRITONSERVER_ServerPollModelRepository will result in\n   an error.\n\n   TRITONSERVER_MODEL_CONTROL_POLL: the models in model repository will be\n   loaded on startup. The model repository can be polled periodically using\n   TRITONSERVER_ServerPollModelRepository and the server will load, unload,\n   and updated models according to changes in the model repository.\n\n   TRITONSERVER_MODEL_CONTROL_EXPLICIT: the models in model repository will\n   not be loaded on startup. The corresponding model control APIs must be\n   called to load / unload a model in the model repository.\n\n \\param options The server options object.\n \\param mode The mode to use for the model control.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetModelControlMode(
        options: *mut TRITONSERVER_ServerOptions,
        mode: TRITONSERVER_ModelControlMode,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the model to be loaded at startup in a server options. The model must be\n present in one, and only one, of the specified model repositories.\n This function can be called multiple times with different model name\n to set multiple startup models.\n Note that it only takes affect on TRITONSERVER_MODEL_CONTROL_EXPLICIT mode.\n\n \\param options The server options object.\n \\param mode_name The name of the model to load on startup.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetStartupModel(
        options: *mut TRITONSERVER_ServerOptions,
        model_name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable strict model configuration handling in a server\n options.\n\n \\param options The server options object.\n \\param strict True to enable strict model configuration handling,\n false to disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetStrictModelConfig(
        options: *mut TRITONSERVER_ServerOptions,
        strict: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the rate limit mode in a server options.\n\n   TRITONSERVER_RATE_LIMIT_EXEC_COUNT: The rate limiting prioritizes the\n   inference execution using the number of times each instance has got a\n   chance to run. The execution gets to run only when its resource\n   constraints are satisfied.\n\n   TRITONSERVER_RATE_LIMIT_OFF: The rate limiting is turned off and the\n   inference gets executed whenever an instance is available.\n\n \\param options The server options object.\n \\param mode The mode to use for the rate limiting. By default, execution\n count is used to determine the priorities.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetRateLimiterMode(
        options: *mut TRITONSERVER_ServerOptions,
        mode: TRITONSERVER_RateLimitMode,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Add resource count for rate limiting.\n\n \\param options The server options object.\n \\param name The name of the resource.\n \\param count The count of the resource.\n \\param device The device identifier for the resource. A value of -1\n indicates that the specified number of resources are available on every\n device. The device value is ignored for a global resource. The server\n will use the rate limiter configuration specified for instance groups\n in model config to determine whether resource is global. In case of\n conflicting resource type in different model configurations, server\n will raise an appropriate error while loading model.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsAddRateLimiterResource(
        options: *mut TRITONSERVER_ServerOptions,
        resource_name: *const ::std::os::raw::c_char,
        resource_count: usize,
        device: ::std::os::raw::c_int,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the total pinned memory byte size that the server can allocate\n in a server options. The pinned memory pool will be shared across\n Triton itself and the backends that use\n TRITONBACKEND_MemoryManager to allocate memory.\n\n \\param options The server options object.\n \\param size The pinned memory pool byte size.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetPinnedMemoryPoolByteSize(
        options: *mut TRITONSERVER_ServerOptions,
        size: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the total CUDA memory byte size that the server can allocate\n on given GPU device in a server options. The pinned memory pool\n will be shared across Triton itself and the backends that use\n TRITONBACKEND_MemoryManager to allocate memory.\n\n \\param options The server options object.\n \\param gpu_device The GPU device to allocate the memory pool.\n \\param size The CUDA memory pool byte size.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetCudaMemoryPoolByteSize(
        options: *mut TRITONSERVER_ServerOptions,
        gpu_device: ::std::os::raw::c_int,
        size: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the total response cache byte size that the server can allocate in CPU\n memory. The response cache will be shared across all inference requests and\n across all models.\n\n \\param options The server options object.\n \\param size The total response cache byte size.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetResponseCacheByteSize(
        options: *mut TRITONSERVER_ServerOptions,
        size: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the minimum support CUDA compute capability in a server\n options.\n\n \\param options The server options object.\n \\param cc The minimum CUDA compute capability.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetMinSupportedComputeCapability(
        options: *mut TRITONSERVER_ServerOptions,
        cc: f64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable exit-on-error in a server options.\n\n \\param options The server options object.\n \\param exit True to enable exiting on intialization error, false\n to continue.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetExitOnError(
        options: *mut TRITONSERVER_ServerOptions,
        exit: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable strict readiness handling in a server options.\n\n \\param options The server options object.\n \\param strict True to enable strict readiness handling, false to\n disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetStrictReadiness(
        options: *mut TRITONSERVER_ServerOptions,
        strict: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the exit timeout, in seconds, for the server in a server\n options.\n\n \\param options The server options object.\n \\param timeout The exit timeout, in seconds.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetExitTimeout(
        options: *mut TRITONSERVER_ServerOptions,
        timeout: ::std::os::raw::c_uint,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the number of threads used in buffer manager in a server options.\n\n \\param options The server options object.\n \\param thread_count The number of threads.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetBufferManagerThreadCount(
        options: *mut TRITONSERVER_ServerOptions,
        thread_count: ::std::os::raw::c_uint,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the number of threads to concurrently load models in a server options.\n\n \\param options The server options object.\n \\param thread_count The number of threads.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetModelLoadThreadCount(
        options: *mut TRITONSERVER_ServerOptions,
        thread_count: ::std::os::raw::c_uint,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Provide a log output file.\n\n \\param options The server options object.\n \\param file a string defining the file where the log outputs will be saved.\n An empty string for the file name will cause triton to direct logging\n facilities to the console\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetLogFile(
        options: *mut TRITONSERVER_ServerOptions,
        file: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable info level logging.\n\n \\param options The server options object.\n \\param log True to enable info logging, false to disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetLogInfo(
        options: *mut TRITONSERVER_ServerOptions,
        log: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable warning level logging.\n\n \\param options The server options object.\n \\param log True to enable warning logging, false to disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetLogWarn(
        options: *mut TRITONSERVER_ServerOptions,
        log: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable error level logging.\n\n \\param options The server options object.\n \\param log True to enable error logging, false to disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetLogError(
        options: *mut TRITONSERVER_ServerOptions,
        log: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the logging format.\n\n \\param options The server options object.\n \\param format The logging format.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetLogFormat(
        options: *mut TRITONSERVER_ServerOptions,
        format: TRITONSERVER_LogFormat,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set verbose logging level. Level zero disables verbose logging.\n\n \\param options The server options object.\n \\param level The verbose logging level.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetLogVerbose(
        options: *mut TRITONSERVER_ServerOptions,
        level: ::std::os::raw::c_int,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable metrics collection in a server options.\n\n \\param options The server options object.\n \\param metrics True to enable metrics, false to disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetMetrics(
        options: *mut TRITONSERVER_ServerOptions,
        metrics: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable GPU metrics collection in a server options. GPU\n metrics are collected if both this option and\n TRITONSERVER_ServerOptionsSetMetrics are true.\n\n \\param options The server options object.\n \\param gpu_metrics True to enable GPU metrics, false to disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetGpuMetrics(
        options: *mut TRITONSERVER_ServerOptions,
        gpu_metrics: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable CPU metrics collection in a server options. CPU\n metrics are collected if both this option and\n TRITONSERVER_ServerOptionsSetMetrics are true.\n\n \\param options The server options object.\n \\param cpu_metrics True to enable CPU metrics, false to disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetCpuMetrics(
        options: *mut TRITONSERVER_ServerOptions,
        cpu_metrics: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the interval for metrics collection in a server options.\n This is 2000 milliseconds by default.\n\n \\param options The server options object.\n \\param metrics_interval_ms The time interval in ms between\n successive metrics updates.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetMetricsInterval(
        options: *mut TRITONSERVER_ServerOptions,
        metrics_interval_ms: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the directory containing backend shared libraries. This\n directory is searched last after the version and model directory\n in the model repository when looking for the backend shared\n library for a model. If the backend is named 'be' the directory\n searched is 'backend_dir'/be/libtriton_be.so.\n\n \\param options The server options object.\n \\param backend_dir The full path of the backend directory.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetBackendDirectory(
        options: *mut TRITONSERVER_ServerOptions,
        backend_dir: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the directory containing repository agent shared libraries. This\n directory is searched when looking for the repository agent shared\n library for a model. If the backend is named 'ra' the directory\n searched is 'repoagent_dir'/ra/libtritonrepoagent_ra.so.\n\n \\param options The server options object.\n \\param repoagent_dir The full path of the repository agent directory.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetRepoAgentDirectory(
        options: *mut TRITONSERVER_ServerOptions,
        repoagent_dir: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Specify the limit on memory usage as a fraction on the device identified by\n 'kind' and 'device_id'. If model loading on the device is requested and the\n current memory usage exceeds the limit, the load will be rejected. If not\n specified, the limit will not be set.\n\n Currently support TRITONSERVER_INSTANCEGROUPKIND_GPU\n\n \\param options The server options object.\n \\param kind The kind of the device.\n \\param device_id The id of the device.\n \\param fraction The limit on memory usage as a fraction\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetModelLoadDeviceLimit(
        options: *mut TRITONSERVER_ServerOptions,
        kind: TRITONSERVER_InstanceGroupKind,
        device_id: ::std::os::raw::c_int,
        fraction: f64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set a configuration setting for a named backend in a server\n options.\n\n \\param options The server options object.\n \\param backend_name The name of the backend.\n \\param setting The name of the setting.\n \\param value The setting value.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetBackendConfig(
        options: *mut TRITONSERVER_ServerOptions,
        backend_name: *const ::std::os::raw::c_char,
        setting: *const ::std::os::raw::c_char,
        value: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set a host policy setting for a given policy name in a server options.\n\n \\param options The server options object.\n \\param policy_name The name of the policy.\n \\param setting The name of the setting.\n \\param value The setting value.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetHostPolicy(
        options: *mut TRITONSERVER_ServerOptions,
        policy_name: *const ::std::os::raw::c_char,
        setting: *const ::std::os::raw::c_char,
        value: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
pub const tritonserver_batchflag_enum_TRITONSERVER_BATCH_UNKNOWN: tritonserver_batchflag_enum = 1;
pub const tritonserver_batchflag_enum_TRITONSERVER_BATCH_FIRST_DIM: tritonserver_batchflag_enum = 2;
#[doc = " Model batch flags. The enum values must be power-of-2 values."]
pub type tritonserver_batchflag_enum = ::std::os::raw::c_uint;
#[doc = " Model batch flags. The enum values must be power-of-2 values."]
pub use self::tritonserver_batchflag_enum as TRITONSERVER_ModelBatchFlag;
pub const tritonserver_modelindexflag_enum_TRITONSERVER_INDEX_FLAG_READY:
    tritonserver_modelindexflag_enum = 1;
#[doc = " Model index flags. The enum values must be power-of-2 values."]
pub type tritonserver_modelindexflag_enum = ::std::os::raw::c_uint;
#[doc = " Model index flags. The enum values must be power-of-2 values."]
pub use self::tritonserver_modelindexflag_enum as TRITONSERVER_ModelIndexFlag;
pub const tritonserver_txn_property_flag_enum_TRITONSERVER_TXN_ONE_TO_ONE:
    tritonserver_txn_property_flag_enum = 1;
pub const tritonserver_txn_property_flag_enum_TRITONSERVER_TXN_DECOUPLED:
    tritonserver_txn_property_flag_enum = 2;
#[doc = " Model transaction policy flags. The enum values must be\n power-of-2 values."]
pub type tritonserver_txn_property_flag_enum = ::std::os::raw::c_uint;
#[doc = " Model transaction policy flags. The enum values must be\n power-of-2 values."]
pub use self::tritonserver_txn_property_flag_enum as TRITONSERVER_ModelTxnPropertyFlag;
extern "C" {
    #[doc = " Create a new server object. The caller takes ownership of the\n TRITONSERVER_Server object and must call TRITONSERVER_ServerDelete\n to release the object.\n\n \\param server Returns the new inference server object.\n \\param options The inference server options object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerNew(
        server: *mut *mut TRITONSERVER_Server,
        options: *mut TRITONSERVER_ServerOptions,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a server object. If server is not already stopped it is\n stopped before being deleted.\n\n \\param server The inference server object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerDelete(server: *mut TRITONSERVER_Server) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Stop a server object. A server can't be restarted once it is\n stopped.\n\n \\param server The inference server object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerStop(server: *mut TRITONSERVER_Server) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Register a new model repository. Not available in polling mode.\n\n \\param server The inference server object.\n \\param repository_path The full path to the model repository.\n \\param name_mapping List of name_mapping parameters. Each mapping has\n the model directory name as its key, overriden model name as its value.\n \\param model_count Number of mappings provided.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerRegisterModelRepository(
        server: *mut TRITONSERVER_Server,
        repository_path: *const ::std::os::raw::c_char,
        name_mapping: *mut *const TRITONSERVER_Parameter,
        mapping_count: u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Unregister a model repository. Not available in polling mode.\n\n \\param server The inference server object.\n \\param repository_path The full path to the model repository.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerUnregisterModelRepository(
        server: *mut TRITONSERVER_Server,
        repository_path: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Check the model repository for changes and update server state\n based on those changes.\n\n \\param server The inference server object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerPollModelRepository(
        server: *mut TRITONSERVER_Server,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Is the server live?\n\n \\param server The inference server object.\n \\param live Returns true if server is live, false otherwise.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerIsLive(
        server: *mut TRITONSERVER_Server,
        live: *mut bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Is the server ready?\n\n \\param server The inference server object.\n \\param ready Returns true if server is ready, false otherwise.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerIsReady(
        server: *mut TRITONSERVER_Server,
        ready: *mut bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Is the model ready?\n\n \\param server The inference server object.\n \\param model_name The name of the model to get readiness for.\n \\param model_version The version of the model to get readiness\n for.  If -1 then the server will choose a version based on the\n model's policy.\n \\param ready Returns true if server is ready, false otherwise.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerModelIsReady(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        model_version: i64,
        ready: *mut bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the batch properties of the model. The properties are\n communicated by a flags value and an (optional) object returned by\n 'voidp'.\n\n   - TRITONSERVER_BATCH_UNKNOWN: Triton cannot determine the\n     batching properties of the model. This means that the model\n     does not support batching in any way that is useable by\n     Triton. The returned 'voidp' value is nullptr.\n\n   - TRITONSERVER_BATCH_FIRST_DIM: The model supports batching\n     along the first dimension of every input and output\n     tensor. Triton schedulers that perform batching can\n     automatically batch inference requests along this dimension.\n     The returned 'voidp' value is nullptr.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\param model_version The version of the model.  If -1 then the\n server will choose a version based on the model's policy.\n \\param flags Returns flags indicating the batch properties of the\n model.\n \\param voidp If non-nullptr, returns a point specific to the\n 'flags' value.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerModelBatchProperties(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        model_version: i64,
        flags: *mut u32,
        voidp: *mut *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the transaction policy of the model. The policy is\n communicated by a flags value.\n\n   - TRITONSERVER_TXN_ONE_TO_ONE: The model generates exactly\n     one response per request.\n\n   - TRITONSERVER_TXN_DECOUPLED: The model may generate zero\n     to many responses per request.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\param model_version The version of the model.  If -1 then the\n server will choose a version based on the model's policy.\n \\param txn_flags Returns flags indicating the transaction policy of the\n model.\n \\param voidp If non-nullptr, returns a point specific to the 'flags' value.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerModelTransactionProperties(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        model_version: i64,
        txn_flags: *mut u32,
        voidp: *mut *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the metadata of the server as a TRITONSERVER_Message object.\n The caller takes ownership of the message object and must call\n TRITONSERVER_MessageDelete to release the object.\n\n \\param server The inference server object.\n \\param server_metadata Returns the server metadata message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerMetadata(
        server: *mut TRITONSERVER_Server,
        server_metadata: *mut *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the metadata of a model as a TRITONSERVER_Message\n object.  The caller takes ownership of the message object and must\n call TRITONSERVER_MessageDelete to release the object.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\param model_version The version of the model.\n If -1 then the server will choose a version based on the model's\n policy.\n \\param model_metadata Returns the model metadata message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerModelMetadata(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        model_version: i64,
        model_metadata: *mut *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the statistics of a model as a TRITONSERVER_Message\n object. The caller takes ownership of the object and must call\n TRITONSERVER_MessageDelete to release the object.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n If empty, then statistics for all available models will be returned,\n and the server will choose a version based on those models' policies.\n \\param model_version The version of the model.  If -1 then the\n server will choose a version based on the model's policy.\n \\param model_stats Returns the model statistics message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerModelStatistics(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        model_version: i64,
        model_stats: *mut *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the configuration of a model as a TRITONSERVER_Message object.\n The caller takes ownership of the message object and must call\n TRITONSERVER_MessageDelete to release the object.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\param model_version The version of the model.  If -1 then the\n server will choose a version based on the model's policy.\n \\param config_version The model configuration will be returned in\n a format matching this version. If the configuration cannot be\n represented in the requested version's format then an error will\n be returned. Currently only version 1 is supported.\n \\param model_config Returns the model config message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerModelConfig(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        model_version: i64,
        config_version: u32,
        model_config: *mut *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the index of all unique models in the model repositories as a\n TRITONSERVER_Message object. The caller takes ownership of the\n message object and must call TRITONSERVER_MessageDelete to release\n the object.\n\n If TRITONSERVER_INDEX_FLAG_READY is set in 'flags' only the models\n that are loaded into the server and ready for inferencing are\n returned.\n\n \\param server The inference server object.\n \\param flags TRITONSERVER_ModelIndexFlag flags that control how to\n collect the index.\n \\param model_index Return the model index message that holds the\n index of all models contained in the server's model repository(s).\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerModelIndex(
        server: *mut TRITONSERVER_Server,
        flags: u32,
        model_index: *mut *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Load the requested model or reload the model if it is already\n loaded. The function does not return until the model is loaded or\n fails to load. Returned error indicates if model loaded\n successfully or not.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerLoadModel(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Load the requested model or reload the model if it is already\n loaded, with load parameters provided. The function does not return until\n the model is loaded or fails to load. Returned error indicates if model\n loaded successfully or not.\n Currently the below parameter names are recognized:\n - \"config\" : string parameter that contains a JSON representation of the\n model configuration. This config will be used for loading the model instead\n of the one in the model directory.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\param parameters The array of load parameters.\n \\param parameter_count The number of parameters.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerLoadModelWithParameters(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        parameters: *mut *const TRITONSERVER_Parameter,
        parameter_count: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Unload the requested model. Unloading a model that is not loaded\n on server has no affect and success code will be returned.\n The function does not wait for the requested model to be fully unload\n and success code will be returned.\n Returned error indicates if model unloaded successfully or not.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerUnloadModel(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Unload the requested model, and also unload any dependent model that\n was loaded along with the requested model (for example, the models composing\n an ensemble). Unloading a model that is not loaded\n on server has no affect and success code will be returned.\n The function does not wait for the requested model and all dependent\n models to be fully unload and success code will be returned.\n Returned error indicates if model unloaded successfully or not.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerUnloadModelAndDependents(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the current metrics for the server. The caller takes ownership\n of the metrics object and must call TRITONSERVER_MetricsDelete to\n release the object.\n\n \\param server The inference server object.\n \\param metrics Returns the metrics.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerMetrics(
        server: *mut TRITONSERVER_Server,
        metrics: *mut *mut TRITONSERVER_Metrics,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Perform inference using the meta-data and inputs supplied by the\n 'inference_request'. If the function returns success, then the\n caller releases ownership of 'inference_request' and must not\n access it in any way after this call, until ownership is returned\n via the 'request_release_fn' callback registered in the request\n object with TRITONSERVER_InferenceRequestSetReleaseCallback.\n\n The function unconditionally takes ownership of 'trace' and so the\n caller must not access it in any way after this call (except in\n the trace activity callbacks) until ownership is returned via the\n trace's release_fn callback.\n\n Responses produced for this request are returned using the\n allocator and callback registered with the request by\n TRITONSERVER_InferenceRequestSetResponseCallback.\n\n \\param server The inference server object.\n \\param inference_request The request object.\n \\param trace The trace object for this request, or nullptr if no\n tracing.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerInferAsync(
        server: *mut TRITONSERVER_Server,
        inference_request: *mut TRITONSERVER_InferenceRequest,
        trace: *mut TRITONSERVER_InferenceTrace,
    ) -> *mut TRITONSERVER_Error;
}
pub const TRITONSERVER_metrickind_enum_TRITONSERVER_METRIC_KIND_COUNTER:
    TRITONSERVER_metrickind_enum = 0;
pub const TRITONSERVER_metrickind_enum_TRITONSERVER_METRIC_KIND_GAUGE:
    TRITONSERVER_metrickind_enum = 1;
#[doc = " TRITONSERVER_MetricKind\n\n Types of metrics recognized by TRITONSERVER.\n"]
pub type TRITONSERVER_metrickind_enum = ::std::os::raw::c_uint;
#[doc = " TRITONSERVER_MetricKind\n\n Types of metrics recognized by TRITONSERVER.\n"]
pub use self::TRITONSERVER_metrickind_enum as TRITONSERVER_MetricKind;
extern "C" {
    #[doc = " Create a new metric family object. The caller takes ownership of the\n TRITONSERVER_MetricFamily object and must call\n TRITONSERVER_MetricFamilyDelete to release the object.\n\n \\param family Returns the new metric family object.\n \\param kind The type of metric family to create.\n \\param name The name of the metric family seen when calling the metrics\n endpoint.\n \\param description The description of the metric family seen when\n calling the metrics endpoint.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricFamilyNew(
        family: *mut *mut TRITONSERVER_MetricFamily,
        kind: TRITONSERVER_MetricKind,
        name: *const ::std::os::raw::c_char,
        description: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a metric family object.\n A struct TRITONSERVER_MetricFamily* object should be deleted AFTER its\n corresponding struct TRITONSERVER_Metric* objects have been deleted.\n Attempting to delete a family before its metrics will return an error.\n\n \\param family The metric family object to delete.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricFamilyDelete(
        family: *mut TRITONSERVER_MetricFamily,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Create a new metric object. The caller takes ownership of the\n TRITONSERVER_Metric object and must call\n TRITONSERVER_MetricDelete to release the object. The caller is also\n responsible for ownership of the labels passed in. Each label can be deleted\n immediately after creating the metric with TRITONSERVER_ParameterDelete\n if not re-using the labels.\n\n \\param metric Returns the new metric object.\n \\param family The metric family to add this new metric to.\n \\param labels The array of labels to associate with this new metric.\n \\param label_count The number of labels.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricNew(
        metric: *mut *mut TRITONSERVER_Metric,
        family: *mut TRITONSERVER_MetricFamily,
        labels: *mut *const TRITONSERVER_Parameter,
        label_count: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a metric object.\n All struct TRITONSERVER_Metric* objects should be deleted BEFORE their\n corresponding struct TRITONSERVER_MetricFamily* objects have been deleted.\n If a family is deleted before its metrics, an error will be returned.\n\n \\param metric The metric object to delete.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricDelete(metric: *mut TRITONSERVER_Metric) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the current value of a metric object.\n Supports metrics of kind TRITONSERVER_METRIC_KIND_COUNTER\n and TRITONSERVER_METRIC_KIND_GAUGE, and returns\n TRITONSERVER_ERROR_UNSUPPORTED for unsupported TRITONSERVER_MetricKind.\n\n \\param metric The metric object to query.\n \\param value Returns the current value of the metric object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricValue(
        metric: *mut TRITONSERVER_Metric,
        value: *mut f64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Increment the current value of metric by value.\n Supports metrics of kind TRITONSERVER_METRIC_KIND_GAUGE for any value,\n and TRITONSERVER_METRIC_KIND_COUNTER for non-negative values. Returns\n TRITONSERVER_ERROR_UNSUPPORTED for unsupported TRITONSERVER_MetricKind\n and TRITONSERVER_ERROR_INVALID_ARG for negative values on a\n TRITONSERVER_METRIC_KIND_COUNTER metric.\n\n \\param metric The metric object to update.\n \\param value The amount to increment the metric's value by.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricIncrement(
        metric: *mut TRITONSERVER_Metric,
        value: f64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the current value of metric to value.\n Supports metrics of kind TRITONSERVER_METRIC_KIND_GAUGE and returns\n TRITONSERVER_ERROR_UNSUPPORTED for unsupported TRITONSERVER_MetricKind.\n\n \\param metric The metric object to update.\n \\param value The amount to set metric's value to.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricSet(
        metric: *mut TRITONSERVER_Metric,
        value: f64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the TRITONSERVER_MetricKind of metric and its corresponding family.\n\n \\param metric The metric object to query.\n \\param kind Returns the TRITONSERVER_MetricKind of metric.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_GetMetricKind(
        metric: *mut TRITONSERVER_Metric,
        kind: *mut TRITONSERVER_MetricKind,
    ) -> *mut TRITONSERVER_Error;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONBACKEND_MemoryManager {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONBACKEND_Input {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONBACKEND_Output {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONBACKEND_State {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONBACKEND_Request {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONBACKEND_ResponseFactory {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONBACKEND_Response {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONBACKEND_Backend {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONBACKEND_Model {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONBACKEND_ModelInstance {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONBACKEND_BackendAttribute {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONBACKEND_Batcher {
    _unused: [u8; 0],
}
extern "C" {
    #[doc = " Get the TRITONBACKEND API version supported by Triton. This value\n can be compared against the TRITONBACKEND_API_VERSION_MAJOR and\n TRITONBACKEND_API_VERSION_MINOR used to build the backend to\n ensure that Triton is compatible with the backend.\n\n \\param major Returns the TRITONBACKEND API major version supported\n by Triton.\n \\param minor Returns the TRITONBACKEND API minor version supported\n by Triton.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ApiVersion(major: *mut u32, minor: *mut u32) -> *mut TRITONSERVER_Error;
}
pub const TRITONBACKEND_artifacttype_enum_TRITONBACKEND_ARTIFACT_FILESYSTEM:
    TRITONBACKEND_artifacttype_enum = 0;
#[doc = " TRITONBACKEND_ArtifactType\n\n The ways that the files that make up a backend or model are\n communicated to the backend.\n\n   TRITONBACKEND_ARTIFACT_FILESYSTEM: The model or backend\n     artifacts are made available to Triton via a locally\n     accessible filesystem. The backend can access these files\n     using an appropriate system API.\n"]
pub type TRITONBACKEND_artifacttype_enum = ::std::os::raw::c_uint;
#[doc = " TRITONBACKEND_ArtifactType\n\n The ways that the files that make up a backend or model are\n communicated to the backend.\n\n   TRITONBACKEND_ARTIFACT_FILESYSTEM: The model or backend\n     artifacts are made available to Triton via a locally\n     accessible filesystem. The backend can access these files\n     using an appropriate system API.\n"]
pub use self::TRITONBACKEND_artifacttype_enum as TRITONBACKEND_ArtifactType;
extern "C" {
    #[doc = " Allocate a contiguous block of memory of a specific type using a\n memory manager. Two error codes have specific interpretations for\n this function:\n\n   TRITONSERVER_ERROR_UNSUPPORTED: Indicates that Triton is\n     incapable of allocating the requested memory type and memory\n     type ID. Requests for the memory type and ID will always fail\n     no matter 'byte_size' of the request.\n\n   TRITONSERVER_ERROR_UNAVAILABLE: Indicates that Triton can\n      allocate the memory type and ID but that currently it cannot\n      allocate a contiguous block of memory of the requested\n      'byte_size'.\n\n \\param manager The memory manager.\n \\param buffer Returns the allocated memory.\n \\param memory_type The type of memory to allocate.\n \\param memory_type_id The ID associated with the memory type to\n allocate. For GPU memory this indicates the device ID of the GPU\n to allocate from.\n \\param byte_size The size of memory to allocate, in bytes.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_MemoryManagerAllocate(
        manager: *mut TRITONBACKEND_MemoryManager,
        buffer: *mut *mut ::std::os::raw::c_void,
        memory_type: TRITONSERVER_MemoryType,
        memory_type_id: i64,
        byte_size: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Free a buffer that was previously allocated with\n TRITONBACKEND_MemoryManagerAllocate. The call must provide the\n same values for 'memory_type' and 'memory_type_id' as were used\n when the buffer was allocate or else the behavior is undefined.\n\n \\param manager The memory manager.\n \\param buffer The allocated memory buffer to free.\n \\param memory_type The type of memory of the buffer.\n \\param memory_type_id The ID associated with the memory type of\n the buffer.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_MemoryManagerFree(
        manager: *mut TRITONBACKEND_MemoryManager,
        buffer: *mut ::std::os::raw::c_void,
        memory_type: TRITONSERVER_MemoryType,
        memory_type_id: i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the name and properties of an input tensor. The returned\n strings and other properties are owned by the input, not the\n caller, and so should not be modified or freed.\n\n \\param input The input tensor.\n \\param name If non-nullptr, returns the tensor name.\n \\param datatype If non-nullptr, returns the tensor datatype.\n \\param shape If non-nullptr, returns the tensor shape.\n \\param dim_count If non-nullptr, returns the number of dimensions\n in the tensor shape.\n \\param byte_size If non-nullptr, returns the size of the available\n data for the tensor, in bytes. This size reflects the actual data\n available, and does not necessarily match what is\n expected/required for the tensor given its shape and datatype. It\n is the responsibility of the backend to handle mismatches in these\n sizes appropriately.\n \\param buffer_count If non-nullptr, returns the number of buffers\n holding the contents of the tensor. These buffers are accessed\n using TRITONBACKEND_InputBuffer.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_InputProperties(
        input: *mut TRITONBACKEND_Input,
        name: *mut *const ::std::os::raw::c_char,
        datatype: *mut TRITONSERVER_DataType,
        shape: *mut *const i64,
        dims_count: *mut u32,
        byte_size: *mut u64,
        buffer_count: *mut u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the name and properties of an input tensor associated with a given\n host policy. If there are no input buffers for the specified  host policy,\n the properties of the fallback input buffers are returned. The returned\n strings and other properties are owned by the input, not the caller, and so\n should not be modified or freed.\n\n \\param input The input tensor.\n \\param host_policy_name The host policy name. Fallback input properties\n will be return if nullptr is provided.\n \\param name If non-nullptr, returns the tensor name.\n \\param datatype If non-nullptr, returns the tensor datatype.\n \\param shape If non-nullptr, returns the tensor shape.\n \\param dim_count If non-nullptr, returns the number of dimensions\n in the tensor shape.\n \\param byte_size If non-nullptr, returns the size of the available\n data for the tensor, in bytes. This size reflects the actual data\n available, and does not necessarily match what is\n expected/required for the tensor given its shape and datatype. It\n is the responsibility of the backend to handle mismatches in these\n sizes appropriately.\n \\param buffer_count If non-nullptr, returns the number of buffers\n holding the contents of the tensor. These buffers are accessed\n using TRITONBACKEND_InputBufferForHostPolicy.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_InputPropertiesForHostPolicy(
        input: *mut TRITONBACKEND_Input,
        host_policy_name: *const ::std::os::raw::c_char,
        name: *mut *const ::std::os::raw::c_char,
        datatype: *mut TRITONSERVER_DataType,
        shape: *mut *const i64,
        dims_count: *mut u32,
        byte_size: *mut u64,
        buffer_count: *mut u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get a buffer holding (part of) the tensor data for an input. For a\n given input the number of buffers composing the input are found\n from 'buffer_count' returned by TRITONBACKEND_InputProperties. The\n returned buffer is owned by the input and so should not be\n modified or freed by the caller. The lifetime of the buffer\n matches that of the input and so the buffer should not be accessed\n after the input tensor object is released.\n\n \\param input The input tensor.\n \\param index The index of the buffer. Must be 0 <= index <\n buffer_count, where buffer_count is the value returned by\n TRITONBACKEND_InputProperties.\n \\param buffer Returns a pointer to a contiguous block of data for\n the named input.\n \\param buffer_byte_size Returns the size, in bytes, of 'buffer'.\n \\param memory_type Acts as both input and output. On input gives\n the buffer memory type preferred by the function caller.  Returns\n the actual memory type of 'buffer'.\n \\param memory_type_id Acts as both input and output. On input\n gives the buffer memory type id preferred by the function caller.\n Returns the actual memory type id of 'buffer'.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_InputBuffer(
        input: *mut TRITONBACKEND_Input,
        index: u32,
        buffer: *mut *const ::std::os::raw::c_void,
        buffer_byte_size: *mut u64,
        memory_type: *mut TRITONSERVER_MemoryType,
        memory_type_id: *mut i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get a buffer holding (part of) the tensor data for an input for a specific\n host policy. If there are no input buffers specified for this host policy,\n the fallback input buffer is returned.\n For a given input the number of buffers composing the input are found\n from 'buffer_count' returned by TRITONBACKEND_InputPropertiesForHostPolicy.\n The returned buffer is owned by the input and so should not be modified or\n freed by the caller. The lifetime of the buffer matches that of the input\n and so the buffer should not be accessed after the input tensor object is\n released.\n\n \\param input The input tensor.\n \\param host_policy_name The host policy name. Fallback input buffer\n will be return if nullptr is provided.\n \\param index The index of the buffer. Must be 0 <= index <\n buffer_count, where buffer_count is the value returned by\n TRITONBACKEND_InputPropertiesForHostPolicy.\n \\param buffer Returns a pointer to a contiguous block of data for\n the named input.\n \\param buffer_byte_size Returns the size, in bytes, of 'buffer'.\n \\param memory_type Acts as both input and output. On input gives\n the buffer memory type preferred by the function caller.  Returns\n the actual memory type of 'buffer'.\n \\param memory_type_id Acts as both input and output. On input\n gives the buffer memory type id preferred by the function caller.\n Returns the actual memory type id of 'buffer'.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_InputBufferForHostPolicy(
        input: *mut TRITONBACKEND_Input,
        host_policy_name: *const ::std::os::raw::c_char,
        index: u32,
        buffer: *mut *const ::std::os::raw::c_void,
        buffer_byte_size: *mut u64,
        memory_type: *mut TRITONSERVER_MemoryType,
        memory_type_id: *mut i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the buffer attributes associated with the given input buffer. For a\n given input the number of buffers composing the input are found from\n 'buffer_count' returned by TRITONBACKEND_InputProperties. The returned\n 'buffer_attributes' is owned by the input and so should not be modified or\n freed by the caller. The lifetime of the 'buffer_attributes' matches that of\n the input and so the 'buffer_attributes' should not be accessed after the\n input tensor object is released.\n\n \\param input The input tensor.\n \\param index The index of the buffer. Must be 0 <= index < buffer_count,\n where buffer_count is the value returned by TRITONBACKEND_InputProperties.\n \\param buffer Returns a pointer to a contiguous block of data for\n the named input.\n \\param buffer_attributes Returns the attributes for the given buffer.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_InputBufferAttributes(
        input: *mut TRITONBACKEND_Input,
        index: u32,
        buffer: *mut *const ::std::os::raw::c_void,
        buffer_attributes: *mut *mut TRITONSERVER_BufferAttributes,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get a buffer to use to hold the tensor data for the output. The\n returned buffer is owned by the output and so should not be freed\n by the caller. The caller can and should fill the buffer with the\n output data for the tensor. The lifetime of the buffer matches\n that of the output and so the buffer should not be accessed after\n the output tensor object is released.\n\n \\param buffer Returns a pointer to a buffer where the contents of\n the output tensor should be placed.\n \\param buffer_byte_size The size, in bytes, of the buffer required\n by the caller.\n \\param memory_type Acts as both input and output. On input gives\n the buffer memory type preferred by the caller.  Returns the\n actual memory type of 'buffer'.\n \\param memory_type_id Acts as both input and output. On input\n gives the buffer memory type id preferred by the caller. Returns\n the actual memory type id of 'buffer'.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_OutputBuffer(
        output: *mut TRITONBACKEND_Output,
        buffer: *mut *mut ::std::os::raw::c_void,
        buffer_byte_size: u64,
        memory_type: *mut TRITONSERVER_MemoryType,
        memory_type_id: *mut i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the buffer attributes associated with the given output buffer. The\n returned 'buffer_attributes' is owned by the output and so should not be\n modified or freed by the caller. The lifetime of the 'buffer_attributes'\n matches that of the output and so the 'buffer_attributes' should not be\n accessed after the output tensor object is released. This function must be\n called after the TRITONBACKEND_OutputBuffer otherwise it might contain\n incorrect data.\n\n \\param output The output tensor.\n \\param buffer_attributes Returns the attributes for the output buffer.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_OutputBufferAttributes(
        output: *mut TRITONBACKEND_Output,
        buffer_attributes: *mut *mut TRITONSERVER_BufferAttributes,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the ID of the request. Can be nullptr if request doesn't have\n an ID. The returned string is owned by the request, not the\n caller, and so should not be modified or freed.\n\n \\param request The inference request.\n \\param id Returns the ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_RequestId(
        request: *mut TRITONBACKEND_Request,
        id: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the correlation ID of the request if it is an unsigned integer.\n Zero indicates that the request does not have a correlation ID.\n Returns failure if correlation ID for given request is not an unsigned\n integer.\n\n \\param request The inference request.\n \\param id Returns the correlation ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_RequestCorrelationId(
        request: *mut TRITONBACKEND_Request,
        id: *mut u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the correlation ID of the request if it is a string.\n Empty string indicates that the request does not have a correlation ID.\n Returns error if correlation ID for given request is not a string.\n\n \\param request The inference request.\n \\param id Returns the correlation ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_RequestCorrelationIdString(
        request: *mut TRITONBACKEND_Request,
        id: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the flag(s) associated with a request. On return 'flags' holds\n a bitwise-or of all flag values, see TRITONSERVER_RequestFlag for\n available flags.\n\n \\param request The inference request.\n \\param flags Returns the flags.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_RequestFlags(
        request: *mut TRITONBACKEND_Request,
        flags: *mut u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the number of input tensors specified in the request.\n\n \\param request The inference request.\n \\param count Returns the number of input tensors.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_RequestInputCount(
        request: *mut TRITONBACKEND_Request,
        count: *mut u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the name of an input tensor. The caller does not own\n the returned string and must not modify or delete it. The lifetime\n of the returned string extends only as long as 'request'.\n\n \\param request The inference request.\n \\param index The index of the input tensor. Must be 0 <= index <\n count, where count is the value returned by\n TRITONBACKEND_RequestInputCount.\n \\param input_name Returns the name of the input tensor\n corresponding to the index.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_RequestInputName(
        request: *mut TRITONBACKEND_Request,
        index: u32,
        input_name: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get a named request input. The lifetime of the returned input\n object matches that of the request and so the input object should\n not be accessed after the request object is released.\n\n \\param request The inference request.\n \\param name The name of the input.\n \\param input Returns the input corresponding to the name.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_RequestInput(
        request: *mut TRITONBACKEND_Request,
        name: *const ::std::os::raw::c_char,
        input: *mut *mut TRITONBACKEND_Input,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get a request input by index. The order of inputs in a given\n request is not necessarily consistent with other requests, even if\n the requests are in the same batch. As a result, you can not\n assume that an index obtained from one request will point to the\n same input in a different request.\n\n The lifetime of the returned input object matches that of the\n request and so the input object should not be accessed after the\n request object is released.\n\n \\param request The inference request.\n \\param index The index of the input tensor. Must be 0 <= index <\n count, where count is the value returned by\n TRITONBACKEND_RequestInputCount.\n \\param input Returns the input corresponding to the index.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_RequestInputByIndex(
        request: *mut TRITONBACKEND_Request,
        index: u32,
        input: *mut *mut TRITONBACKEND_Input,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the number of output tensors requested to be returned in the\n request.\n\n \\param request The inference request.\n \\param count Returns the number of output tensors.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_RequestOutputCount(
        request: *mut TRITONBACKEND_Request,
        count: *mut u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the name of a requested output tensor. The caller does not own\n the returned string and must not modify or delete it. The lifetime\n of the returned string extends only as long as 'request'.\n\n \\param request The inference request.\n \\param index The index of the requested output tensor. Must be 0\n <= index < count, where count is the value returned by\n TRITONBACKEND_RequestOutputCount.\n \\param output_name Returns the name of the requested output tensor\n corresponding to the index.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_RequestOutputName(
        request: *mut TRITONBACKEND_Request,
        index: u32,
        output_name: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Returns the preferred memory type and memory type ID of the output buffer\n for the request. As much as possible, Triton will attempt to return\n the same memory_type and memory_type_id values that will be returned by\n the subsequent call to TRITONBACKEND_OutputBuffer, however, the backend must\n be capable of handling cases where the values differ.\n\n \\param request The request.\n \\param name The name of the output tensor. This is optional\n and it should be set to nullptr to indicate that the tensor name has\n not determined.\n \\param byte_size The expected size of the buffer. This is optional\n and it should be set to nullptr to indicate that the byte size has\n not determined.\n \\param memory_type Acts as both input and output. On input gives\n the memory type preferred by the caller. Returns memory type preferred\n by Triton, taken account of the caller preferred type.\n \\param memory_type_id Acts as both input and output. On input gives\n the memory type ID preferred by the caller. Returns memory type ID preferred\n by Triton, taken account of the caller preferred type ID.\n \\return a TRITONSERVER_Error object if a failure occurs.\n A TRITONSERVER_ERROR_UNAVAILABLE error indicates that the properties are not\n available, other error codes indicate an error."]
    pub fn TRITONBACKEND_RequestOutputBufferProperties(
        request: *mut TRITONBACKEND_Request,
        name: *const ::std::os::raw::c_char,
        byte_size: *mut usize,
        memory_type: *mut TRITONSERVER_MemoryType,
        memory_type_id: *mut i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Release the request. The request should be released when it is no\n longer needed by the backend. If this call returns with an error\n (i.e. non-nullptr) then the request was not released and ownership\n remains with the backend. If this call returns with success, the\n 'request' object is no longer owned by the backend and must not be\n used. Any tensor names, data types, shapes, input tensors,\n etc. returned by struct TRITONBACKEND_Request* functions for this request\n are no longer valid. If a persistent copy of that data is required\n it must be created before calling this function.\n\n \\param request The inference request.\n \\param release_flags Flags indicating what type of request release\n should be performed. \\see TRITONSERVER_RequestReleaseFlag. \\see\n TRITONSERVER_InferenceRequestReleaseFn_t.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_RequestRelease(
        request: *mut TRITONBACKEND_Request,
        release_flags: u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Create the response factory associated with a request.\n\n \\param factory Returns the new response factory.\n \\param request The inference request.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ResponseFactoryNew(
        factory: *mut *mut TRITONBACKEND_ResponseFactory,
        request: *mut TRITONBACKEND_Request,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Destroy a response factory.\n\n \\param factory The response factory.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ResponseFactoryDelete(
        factory: *mut TRITONBACKEND_ResponseFactory,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Send response flags without a corresponding response.\n\n \\param factory The response factory.\n \\param send_flags Flags to send. \\see\n TRITONSERVER_ResponseCompleteFlag. \\see\n TRITONSERVER_InferenceResponseCompleteFn_t.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ResponseFactorySendFlags(
        factory: *mut TRITONBACKEND_ResponseFactory,
        send_flags: u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Create a response for a request.\n\n \\param response Returns the new response.\n \\param request The request.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ResponseNew(
        response: *mut *mut TRITONBACKEND_Response,
        request: *mut TRITONBACKEND_Request,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Create a response using a factory.\n\n \\param response Returns the new response.\n \\param factory The response factory.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ResponseNewFromFactory(
        response: *mut *mut TRITONBACKEND_Response,
        factory: *mut TRITONBACKEND_ResponseFactory,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Destroy a response. It is not necessary to delete a response if\n TRITONBACKEND_ResponseSend is called as that function transfers\n ownership of the response object to Triton.\n\n \\param response The response.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ResponseDelete(
        response: *mut TRITONBACKEND_Response,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set a string parameter in the response.\n\n \\param response The response.\n \\param name The name of the parameter.\n \\param value The value of the parameter.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ResponseSetStringParameter(
        response: *mut TRITONBACKEND_Response,
        name: *const ::std::os::raw::c_char,
        value: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set an integer parameter in the response.\n\n \\param response The response.\n \\param name The name of the parameter.\n \\param value The value of the parameter.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ResponseSetIntParameter(
        response: *mut TRITONBACKEND_Response,
        name: *const ::std::os::raw::c_char,
        value: i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set an boolean parameter in the response.\n\n \\param response The response.\n \\param name The name of the parameter.\n \\param value The value of the parameter.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ResponseSetBoolParameter(
        response: *mut TRITONBACKEND_Response,
        name: *const ::std::os::raw::c_char,
        value: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Create an output tensor in the response. The lifetime of the\n returned output tensor object matches that of the response and so\n the output tensor object should not be accessed after the response\n object is deleted.\n\n \\param response The response.\n \\param output Returns the new response output.\n \\param name The name of the output tensor.\n \\param datatype The datatype of the output tensor.\n \\param shape The shape of the output tensor.\n \\param dims_count The number of dimensions in the output tensor\n shape.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ResponseOutput(
        response: *mut TRITONBACKEND_Response,
        output: *mut *mut TRITONBACKEND_Output,
        name: *const ::std::os::raw::c_char,
        datatype: TRITONSERVER_DataType,
        shape: *const i64,
        dims_count: u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Send a response. Calling this function transfers ownership of the\n response object to Triton. The caller must not access or delete\n the response object after calling this function.\n\n \\param response The response.\n \\param send_flags Flags associated with the response. \\see\n TRITONSERVER_ResponseCompleteFlag. \\see\n TRITONSERVER_InferenceResponseCompleteFn_t.\n \\param error The TRITONSERVER_Error to send if the response is an\n error, or nullptr if the response is successful.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ResponseSend(
        response: *mut TRITONBACKEND_Response,
        send_flags: u32,
        error: *mut TRITONSERVER_Error,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Create a state in the request. The returned state object is only valid\n before the TRITONBACKEND_StateUpdate is called. The state should not be\n freed by the caller. If TRITONBACKEND_StateUpdate is not called, the\n lifetime of the state matches the lifetime of the request. If the state name\n does not exist in the \"state\" section of the model configuration, the state\n will not be created and an error will be returned. If this function is\n called when sequence batching is not enabled or there is no 'states' section\n in the sequence batching section of the model configuration, this call will\n return an error.\n\n \\param state Returns the new state.\n \\param request The request.\n \\param name The name of the state.\n \\param datatype The datatype of the state.\n \\param shape The shape of the state.\n \\param dims_count The number of dimensions in the state shape.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_StateNew(
        state: *mut *mut TRITONBACKEND_State,
        request: *mut TRITONBACKEND_Request,
        name: *const ::std::os::raw::c_char,
        datatype: TRITONSERVER_DataType,
        shape: *const i64,
        dims_count: u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Update the state for the sequence. Calling this function will replace the\n state stored for this seqeunce in Triton with 'state' provided in the\n function argument. If this function is called when sequence batching is not\n enabled or there is no 'states' section in the sequence batching section of\n the model configuration, this call will return an error. The backend is not\n required to call this function. If the backend doesn't call\n TRITONBACKEND_StateUpdate function, this particular state for the sequence\n will not be updated and the next inference request in the sequence will use\n the same state as the current inference request.\n\n \\param state The state.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_StateUpdate(state: *mut TRITONBACKEND_State) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get a buffer to use to hold the tensor data for the state. The returned\n buffer is owned by the state and so should not be freed by the caller. The\n caller can and should fill the buffer with the state data. The buffer must\n not be accessed by the backend after TRITONBACKEND_StateUpdate is called.\n The caller should fill the buffer before calling TRITONBACKEND_StateUpdate.\n\n \\param state The state.\n \\param buffer Returns a pointer to a buffer where the contents of the state\n should be placed.\n \\param buffer_byte_size The size, in bytes, of the buffer required\n by the caller.\n \\param memory_type Acts as both input and output. On input gives\n the buffer memory type preferred by the caller.  Returns the\n actual memory type of 'buffer'.\n \\param memory_type_id Acts as both input and output. On input\n gives the buffer memory type id preferred by the caller. Returns\n the actual memory type id of 'buffer'.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_StateBuffer(
        state: *mut TRITONBACKEND_State,
        buffer: *mut *mut ::std::os::raw::c_void,
        buffer_byte_size: u64,
        memory_type: *mut TRITONSERVER_MemoryType,
        memory_type_id: *mut i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the buffer attributes associated with the given state buffer.\n The returned 'buffer_attributes' is owned by the state and so should not be\n modified or freed by the caller. The lifetime of the 'buffer_attributes'\n matches that of the state.\n\n \\param state The state.\n \\param buffer_attributes Returns the buffer attributes for the given state.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_StateBufferAttributes(
        state: *mut TRITONBACKEND_State,
        buffer_attributes: *mut *mut TRITONSERVER_BufferAttributes,
    ) -> *mut TRITONSERVER_Error;
}
pub const TRITONBACKEND_execpolicy_enum_TRITONBACKEND_EXECUTION_BLOCKING:
    TRITONBACKEND_execpolicy_enum = 0;
pub const TRITONBACKEND_execpolicy_enum_TRITONBACKEND_EXECUTION_DEVICE_BLOCKING:
    TRITONBACKEND_execpolicy_enum = 1;
#[doc = " TRITONBACKEND_ExecutionPolicy\n\n Types of execution policy that can be implemented by a backend.\n\n   TRITONBACKEND_EXECUTION_BLOCKING: An instance of the model\n     blocks in TRITONBACKEND_ModelInstanceExecute until it is ready\n     to handle another inference. Upon returning from\n     TRITONBACKEND_ModelInstanceExecute, Triton may immediately\n     call TRITONBACKEND_ModelInstanceExecute for the same instance\n     to execute a new batch of requests. Thus, most backends using\n     this policy will not return from\n     TRITONBACKEND_ModelInstanceExecute until all responses have\n     been sent and all requests have been released. This is the\n     default execution policy.\n\n   TRITONBACKEND_EXECUTION_DEVICE_BLOCKING: An instance, A, of the\n     model blocks in TRITONBACKEND_ModelInstanceExecute if the\n     device associated with the instance is unable to handle\n     another inference. Even if another instance, B, associated\n     with the device, is available and ready to perform an\n     inference, Triton will not invoke\n     TRITONBACKEND_ModeInstanceExecute for B until A returns from\n     TRITONBACKEND_ModelInstanceExecute. Triton will not be blocked\n     from calling TRITONBACKEND_ModelInstanceExecute for instance\n     C, which is associated with a different device than A and B,\n     even if A or B has not returned from\n     TRITONBACKEND_ModelInstanceExecute. This execution policy is\n     typically used by a backend that can cooperatively execute\n     multiple model instances on the same device.\n"]
pub type TRITONBACKEND_execpolicy_enum = ::std::os::raw::c_uint;
#[doc = " TRITONBACKEND_ExecutionPolicy\n\n Types of execution policy that can be implemented by a backend.\n\n   TRITONBACKEND_EXECUTION_BLOCKING: An instance of the model\n     blocks in TRITONBACKEND_ModelInstanceExecute until it is ready\n     to handle another inference. Upon returning from\n     TRITONBACKEND_ModelInstanceExecute, Triton may immediately\n     call TRITONBACKEND_ModelInstanceExecute for the same instance\n     to execute a new batch of requests. Thus, most backends using\n     this policy will not return from\n     TRITONBACKEND_ModelInstanceExecute until all responses have\n     been sent and all requests have been released. This is the\n     default execution policy.\n\n   TRITONBACKEND_EXECUTION_DEVICE_BLOCKING: An instance, A, of the\n     model blocks in TRITONBACKEND_ModelInstanceExecute if the\n     device associated with the instance is unable to handle\n     another inference. Even if another instance, B, associated\n     with the device, is available and ready to perform an\n     inference, Triton will not invoke\n     TRITONBACKEND_ModeInstanceExecute for B until A returns from\n     TRITONBACKEND_ModelInstanceExecute. Triton will not be blocked\n     from calling TRITONBACKEND_ModelInstanceExecute for instance\n     C, which is associated with a different device than A and B,\n     even if A or B has not returned from\n     TRITONBACKEND_ModelInstanceExecute. This execution policy is\n     typically used by a backend that can cooperatively execute\n     multiple model instances on the same device.\n"]
pub use self::TRITONBACKEND_execpolicy_enum as TRITONBACKEND_ExecutionPolicy;
extern "C" {
    #[doc = " Get the name of the backend. The caller does not own the returned\n string and must not modify or delete it. The lifetime of the\n returned string extends only as long as 'backend'.\n\n \\param backend The backend.\n \\param name Returns the name of the backend.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_BackendName(
        backend: *mut TRITONBACKEND_Backend,
        name: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the backend configuration.  The 'backend_config' message is\n owned by Triton and should not be modified or freed by the caller.\n\n The backend configuration, as JSON, is:\n\n   {\n     \"cmdline\" : {\n       \"<setting>\" : \"<value>\",\n       ...\n     }\n   }\n\n \\param backend The backend.\n \\param backend_config Returns the backend configuration as a message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_BackendConfig(
        backend: *mut TRITONBACKEND_Backend,
        backend_config: *mut *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the execution policy for this backend. By default the\n execution policy is TRITONBACKEND_EXECUTION_BLOCKING.\n\n \\param backend The backend.\n \\param policy Returns the execution policy.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_BackendExecutionPolicy(
        backend: *mut TRITONBACKEND_Backend,
        policy: *mut TRITONBACKEND_ExecutionPolicy,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the execution policy for this backend. By default the\n execution policy is TRITONBACKEND_EXECUTION_BLOCKING. Triton reads\n the backend's execution policy after calling\n TRITONBACKEND_Initialize, so to be recognized changes to the\n execution policy must be made in TRITONBACKEND_Initialize.\n Also, note that if using sequence batcher for the model, Triton will\n use TRITONBACKEND_EXECUTION_BLOCKING policy irrespective of the\n policy specified by this setter function.\n\n \\param backend The backend.\n \\param policy The execution policy.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_BackendSetExecutionPolicy(
        backend: *mut TRITONBACKEND_Backend,
        policy: TRITONBACKEND_ExecutionPolicy,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the location of the files that make up the backend\n implementation. This location contains the backend shared library\n and any other files located with the shared library. The\n 'location' communicated depends on how the backend is being\n communicated to Triton as indicated by 'artifact_type'.\n\n   TRITONBACKEND_ARTIFACT_FILESYSTEM: The backend artifacts are\n     made available to Triton via the local filesytem. 'location'\n     returns the full path to the directory containing this\n     backend's artifacts. The returned string is owned by Triton,\n     not the caller, and so should not be modified or freed.\n\n \\param backend The backend.\n \\param artifact_type Returns the artifact type for the backend.\n \\param path Returns the location.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_BackendArtifacts(
        backend: *mut TRITONBACKEND_Backend,
        artifact_type: *mut TRITONBACKEND_ArtifactType,
        location: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the memory manager associated with a backend.\n\n \\param backend The backend.\n \\param manager Returns the memory manager.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_BackendMemoryManager(
        backend: *mut TRITONBACKEND_Backend,
        manager: *mut *mut TRITONBACKEND_MemoryManager,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the user-specified state associated with the backend. The\n state is completely owned and managed by the backend.\n\n \\param backend The backend.\n \\param state Returns the user state, or nullptr if no user state.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_BackendState(
        backend: *mut TRITONBACKEND_Backend,
        state: *mut *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the user-specified state associated with the backend. The\n state is completely owned and managed by the backend.\n\n \\param backend The backend.\n \\param state The user state, or nullptr if no user state.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_BackendSetState(
        backend: *mut TRITONBACKEND_Backend,
        state: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the name of the model. The returned string is owned by the\n model object, not the caller, and so should not be modified or\n freed.\n\n \\param model The model.\n \\param name Returns the model name.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelName(
        model: *mut TRITONBACKEND_Model,
        name: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the version of the model.\n\n \\param model The model.\n \\param version Returns the model version.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelVersion(
        model: *mut TRITONBACKEND_Model,
        version: *mut u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the location of the files that make up the model. The\n 'location' communicated depends on how the model is being\n communicated to Triton as indicated by 'artifact_type'.\n\n   TRITONBACKEND_ARTIFACT_FILESYSTEM: The model artifacts are made\n     available to Triton via the local filesytem. 'location'\n     returns the full path to the directory in the model repository\n     that contains this model's artifacts. The returned string is\n     owned by Triton, not the caller, and so should not be modified\n     or freed.\n\n \\param model The model.\n \\param artifact_type Returns the artifact type for the model.\n \\param path Returns the location.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelRepository(
        model: *mut TRITONBACKEND_Model,
        artifact_type: *mut TRITONBACKEND_ArtifactType,
        location: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the model configuration. The caller takes ownership of the\n message object and must call TRITONSERVER_MessageDelete to release\n the object. The configuration is available via this call even\n before the model is loaded and so can be used in\n TRITONBACKEND_ModelInitialize. TRITONSERVER_ServerModelConfig\n returns equivalent information but is not useable until after the\n model loads.\n\n \\param model The model.\n \\param config_version The model configuration will be returned in\n a format matching this version. If the configuration cannot be\n represented in the requested version's format then an error will\n be returned. Currently only version 1 is supported.\n \\param model_config Returns the model configuration as a message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelConfig(
        model: *mut TRITONBACKEND_Model,
        config_version: u32,
        model_config: *mut *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Whether the backend should attempt to auto-complete the model configuration.\n If true, the model should fill the inputs, outputs, and max batch size in\n the model configuration if incomplete. If the model configuration is\n changed,  the new configuration must be reported to Triton using\n TRITONBACKEND_ModelSetConfig.\n\n \\param model The model.\n \\param auto_complete_config Returns whether the backend should auto-complete\n the model configuration.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelAutoCompleteConfig(
        model: *mut TRITONBACKEND_Model,
        auto_complete_config: *mut bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the model configuration in Triton server. This API should only be called\n when the backend implements the auto-completion of model configuration\n and TRITONBACKEND_ModelAutoCompleteConfig returns true in\n auto_complete_config. Only the inputs, outputs, max batch size, and\n scheduling choice can be changed. A caveat being scheduling choice can only\n be changed if none is previously set. Any other changes to the model\n configuration will be ignored by Triton. This function can only be called\n from TRITONBACKEND_ModelInitialize, calling in any other context will result\n in an error being returned. Additionally, Triton server can add some of the\n missing fields in the provided config with this call. The backend must get\n the complete configuration again by using TRITONBACKEND_ModelConfig.\n TRITONBACKEND_ModelSetConfig does not take ownership of the message object\n and so the caller should call TRITONSERVER_MessageDelete to release the\n object once the function returns.\n\n \\param model The model.\n \\param config_version The format version of the model configuration.\n If the configuration is not represented in the version's format\n then an error will be returned. Currently only version 1 is supported.\n \\param model_config The updated model configuration as a message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelSetConfig(
        model: *mut TRITONBACKEND_Model,
        config_version: u32,
        model_config: *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the TRITONSERVER_Server object that this model is being served\n by.\n\n \\param model The model.\n \\param server Returns the server.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelServer(
        model: *mut TRITONBACKEND_Model,
        server: *mut *mut TRITONSERVER_Server,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the backend used by the model.\n\n \\param model The model.\n \\param model Returns the backend object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelBackend(
        model: *mut TRITONBACKEND_Model,
        backend: *mut *mut TRITONBACKEND_Backend,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the user-specified state associated with the model. The\n state is completely owned and managed by the backend.\n\n \\param model The model.\n \\param state Returns the user state, or nullptr if no user state.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelState(
        model: *mut TRITONBACKEND_Model,
        state: *mut *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the user-specified state associated with the model. The\n state is completely owned and managed by the backend.\n\n \\param model The model.\n \\param state The user state, or nullptr if no user state.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelSetState(
        model: *mut TRITONBACKEND_Model,
        state: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the name of the model instance. The returned string is owned by the\n model object, not the caller, and so should not be modified or\n freed.\n\n \\param instance The model instance.\n \\param name Returns the instance name.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceName(
        instance: *mut TRITONBACKEND_ModelInstance,
        name: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the kind of the model instance.\n\n \\param instance The model instance.\n \\param kind Returns the instance kind.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceKind(
        instance: *mut TRITONBACKEND_ModelInstance,
        kind: *mut TRITONSERVER_InstanceGroupKind,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the device ID of the model instance.\n\n \\param instance The model instance.\n \\param device_id Returns the instance device ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceDeviceId(
        instance: *mut TRITONBACKEND_ModelInstance,
        device_id: *mut i32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the host policy setting.  The 'host_policy' message is\n owned by Triton and should not be modified or freed by the caller.\n\n The host policy setting, as JSON, is:\n\n   {\n     \"<host_policy>\" : {\n       \"<setting>\" : \"<value>\",\n       ...\n     }\n   }\n\n \\param instance The model instance.\n \\param host_policy Returns the host policy setting as a message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceHostPolicy(
        instance: *mut TRITONBACKEND_ModelInstance,
        host_policy: *mut *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Whether the model instance is passive.\n\n \\param instance The model instance.\n \\param is_passive Returns true if the instance is passive, false otherwise\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceIsPassive(
        instance: *mut TRITONBACKEND_ModelInstance,
        is_passive: *mut bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the number of optimization profiles to be loaded for the instance.\n\n \\param instance The model instance.\n \\param count Returns the number of optimization profiles.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceProfileCount(
        instance: *mut TRITONBACKEND_ModelInstance,
        count: *mut u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the name of optimization profile. The caller does not own\n the returned string and must not modify or delete it. The lifetime\n of the returned string extends only as long as 'instance'.\n\n \\param instance The model instance.\n \\param index The index of the optimization profile. Must be 0\n <= index < count, where count is the value returned by\n TRITONBACKEND_ModelInstanceProfileCount.\n \\param profile_name Returns the name of the optimization profile\n corresponding to the index.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceProfileName(
        instance: *mut TRITONBACKEND_ModelInstance,
        index: u32,
        profile_name: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the number of secondary devices configured for the instance.\n\n \\param instance The model instance.\n \\param count Returns the number of secondary devices.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceSecondaryDeviceCount(
        instance: *mut TRITONBACKEND_ModelInstance,
        count: *mut u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the properties of indexed secondary device. The returned\n strings and other properties are owned by the instance, not the\n caller, and so should not be modified or freed.\n\n \\param instance The model instance.\n \\param index The index of the secondary device. Must be 0\n <= index < count, where count is the value returned by\n TRITONBACKEND_ModelInstanceSecondaryDeviceCount.\n \\param kind Returns the kind of secondary device corresponding\n to the index.\n \\param id Returns the id of secondary device corresponding to the index.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceSecondaryDeviceProperties(
        instance: *mut TRITONBACKEND_ModelInstance,
        index: u32,
        kind: *mut *const ::std::os::raw::c_char,
        id: *mut i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the model associated with a model instance.\n\n \\param instance The model instance.\n \\param backend Returns the model object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceModel(
        instance: *mut TRITONBACKEND_ModelInstance,
        model: *mut *mut TRITONBACKEND_Model,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the user-specified state associated with the model\n instance. The state is completely owned and managed by the\n backend.\n\n \\param instance The model instance.\n \\param state Returns the user state, or nullptr if no user state.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceState(
        instance: *mut TRITONBACKEND_ModelInstance,
        state: *mut *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the user-specified state associated with the model\n instance. The state is completely owned and managed by the\n backend.\n\n \\param instance The model instance.\n \\param state The user state, or nullptr if no user state.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceSetState(
        instance: *mut TRITONBACKEND_ModelInstance,
        state: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Record statistics for an inference request.\n\n Set 'success' true to indicate that the inference request\n completed successfully. In this case all timestamps should be\n non-zero values reported in nanoseconds and should be collected\n using std::chrono::steady_clock::now().time_since_epoch() or the equivalent.\n Set 'success' to false to indicate that the inference request failed\n to complete successfully. In this case all timestamps values are\n ignored.\n\n For consistency of measurement across different backends, the\n timestamps should be collected at the following points during\n TRITONBACKEND_ModelInstanceExecute.\n\n   TRITONBACKEND_ModelInstanceExecute()\n     CAPTURE TIMESPACE (exec_start_ns)\n     < process input tensors to prepare them for inference\n       execution, including copying the tensors to/from GPU if\n       necessary>\n     CAPTURE TIMESPACE (compute_start_ns)\n     < perform inference computations to produce outputs >\n     CAPTURE TIMESPACE (compute_end_ns)\n     < allocate output buffers and extract output tensors, including\n       copying the tensors to/from GPU if necessary>\n     CAPTURE TIMESPACE (exec_end_ns)\n     return\n\n Note that these statistics are associated with a valid\n TRITONBACKEND_Request object and so must be reported before the\n request is released. For backends that release the request before\n all response(s) are sent, these statistics cannot capture\n information about the time required to produce the response.\n\n \\param instance The model instance.\n \\param request The inference request that statistics are being\n reported for.\n \\param success True if the inference request completed\n successfully, false if it failed to complete.\n \\param exec_start_ns Timestamp for the start of execution.\n \\param compute_start_ns Timestamp for the start of execution\n computations.\n \\param compute_end_ns Timestamp for the end of execution\n computations.\n \\param exec_end_ns Timestamp for the end of execution.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceReportStatistics(
        instance: *mut TRITONBACKEND_ModelInstance,
        request: *mut TRITONBACKEND_Request,
        success: bool,
        exec_start_ns: u64,
        compute_start_ns: u64,
        compute_end_ns: u64,
        exec_end_ns: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Record statistics for the execution of an entire batch of\n inference requests.\n\n All timestamps should be non-zero values reported in nanoseconds\n and should be collected using\n std::chrono::steady_clock::now().time_since_epoch() or the equivalent.\n See TRITONBACKEND_ModelInstanceReportStatistics for more information about\n the timestamps.\n\n 'batch_size' is the sum of the batch sizes for the individual\n requests that were delivered together in the call to\n TRITONBACKEND_ModelInstanceExecute. For example, if three requests\n are passed to TRITONBACKEND_ModelInstanceExecute and those\n requests have batch size 1, 2, and 3; then 'batch_size' should be\n set to 6.\n\n \\param instance The model instance.\n \\param batch_size Combined batch size of all the individual\n requests executed in the batch.\n \\param exec_start_ns Timestamp for the start of execution.\n \\param compute_start_ns Timestamp for the start of execution\n computations.\n \\param compute_end_ns Timestamp for the end of execution\n computations.\n \\param exec_end_ns Timestamp for the end of execution.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceReportBatchStatistics(
        instance: *mut TRITONBACKEND_ModelInstance,
        batch_size: u64,
        exec_start_ns: u64,
        compute_start_ns: u64,
        compute_end_ns: u64,
        exec_end_ns: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Initialize a backend. This function is optional, a backend is not\n required to implement it. This function is called once when a\n backend is loaded to allow the backend to initialize any state\n associated with the backend. A backend has a single state that is\n shared across all models that use the backend.\n\n \\param backend The backend.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_Initialize(backend: *mut TRITONBACKEND_Backend)
        -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Finalize for a backend. This function is optional, a backend is\n not required to implement it. This function is called once, just\n before the backend is unloaded. All state associated with the\n backend should be freed and any threads created for the backend\n should be exited/joined before returning from this function.\n\n \\param backend The backend.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_Finalize(backend: *mut TRITONBACKEND_Backend) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Initialize for a model. This function is optional, a backend is\n not required to implement it. This function is called once when a\n model that uses the backend is loaded to allow the backend to\n initialize any state associated with the model. The backend should\n also examine the model configuration to determine if the\n configuration is suitable for the backend. Any errors reported by\n this function will prevent the model from loading.\n\n \\param model The model.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInitialize(
        model: *mut TRITONBACKEND_Model,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Finalize for a model. This function is optional, a backend is not\n required to implement it. This function is called once for a\n model, just before the model is unloaded from Triton. All state\n associated with the model should be freed and any threads created\n for the model should be exited/joined before returning from this\n function.\n\n \\param model The model.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelFinalize(model: *mut TRITONBACKEND_Model) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Initialize for a model instance. This function is optional, a\n backend is not required to implement it. This function is called\n once when a model instance is created to allow the backend to\n initialize any state associated with the instance.\n\n \\param instance The model instance.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceInitialize(
        instance: *mut TRITONBACKEND_ModelInstance,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Finalize for a model instance. This function is optional, a\n backend is not required to implement it. This function is called\n once for an instance, just before the corresponding model is\n unloaded from Triton. All state associated with the instance\n should be freed and any threads created for the instance should be\n exited/joined before returning from this function.\n\n \\param instance The model instance.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceFinalize(
        instance: *mut TRITONBACKEND_ModelInstance,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Execute a batch of one or more requests on a model instance. This\n function is required. Triton will not perform multiple\n simultaneous calls to this function for a given model 'instance';\n however, there may be simultaneous calls for different model\n instances (for the same or different models).\n\n If an error is returned the ownership of the request objects\n remains with Triton and the backend must not retain references to\n the request objects or access them in any way.\n\n If success is returned, ownership of the request objects is\n transferred to the backend and it is then responsible for creating\n responses and releasing the request objects. Note that even though\n ownership of the request objects is transferred to the backend, the\n ownership of the buffer holding request pointers is returned back\n to Triton upon return from TRITONBACKEND_ModelInstanceExecute. If\n any request objects need to be maintained beyond\n TRITONBACKEND_ModelInstanceExecute, then the pointers must be copied\n out of the array within TRITONBACKEND_ModelInstanceExecute.\n\n \\param instance The model instance.\n \\param requests The requests.\n \\param request_count The number of requests in the batch.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelInstanceExecute_wip(
        instance: *mut TRITONBACKEND_ModelInstance,
        requests: *mut *mut TRITONBACKEND_Request,
        request_count: u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Query the backend for different model attributes. This function is optional,\n a backend is not required to implement it. The backend is also not required\n to set all backend attribute listed. This function is called when\n Triton requires further backend / model information to perform operations.\n This function may be called multiple times within the lifetime of the\n backend (between TRITONBACKEND_Initialize and TRITONBACKEND_Finalize).\n The backend may return error to indicate failure to set the backend\n attributes, and the attributes specified in the same function call will be\n ignored. Triton will update the specified attributes if 'nullptr' is\n returned.\n\n \\param backend The backend.\n \\param backend_attributes Return the backend attribute.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_GetBackendAttribute(
        backend: *mut TRITONBACKEND_Backend,
        backend_attributes: *mut TRITONBACKEND_BackendAttribute,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Add the preferred instance group of the backend. This function\n can be called multiple times to cover different instance group kinds that\n the backend supports, given the priority order that the first call describes\n the most preferred group. In the case where instance group are not\n explicitly provided, Triton will use this attribute to create model\n deployment that aligns more with the backend preference.\n\n \\param backend_attributes The backend attributes object.\n \\param kind The kind of the instance group.\n \\param count The number of instances per device. Triton default will be used\n if 0 is provided.\n \\param device_ids The devices where instances should be available. Triton\n default will be used if 'nullptr' is provided.\n \\param id_count The number of devices in 'device_ids'.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_BackendAttributeAddPreferredInstanceGroup(
        backend_attributes: *mut TRITONBACKEND_BackendAttribute,
        kind: TRITONSERVER_InstanceGroupKind,
        count: u64,
        device_ids: *const u64,
        id_count: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Create a new batcher for use with custom batching. This is called during\n model loading. The batcher will point to a user-defined data structure that\n holds read-only data used for custom batching.\n\n \\param batcher User-defined placeholder for backend to store and\n retrieve information about the batching strategy for this\n model.RITONBACKEND_ISPEC return a TRITONSERVER_Error indicating success or\n failure. \\param model The backend model for which Triton is forming a batch.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelBatcherInitialize(
        batcher: *mut *mut TRITONBACKEND_Batcher,
        model: *mut TRITONBACKEND_Model,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Free memory associated with batcher. This is called during model unloading.\n\n \\param batcher User-defined placeholder for backend to store and\n retrieve information about the batching strategy for this model.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelBatcherFinalize(
        batcher: *mut TRITONBACKEND_Batcher,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Check whether a request should be added to the pending model batch.\n\n \\param request The request to be added to the pending batch.\n \\param userp The placeholder for backend to store and retrieve information\n about this pending batch. When the callback returns, this should reflect\n the latest batch information.\n \\param should_include The pointer to be updated on whether the request\n should be included in the batch.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelBatchIncludeRequest(
        request: *mut TRITONBACKEND_Request,
        userp: *mut ::std::os::raw::c_void,
        should_include: *mut bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " \\param userp The placeholder for backend to store and retrieve information\n about this pending batch.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelBatchInitialize(
        batcher: *const TRITONBACKEND_Batcher,
        userp: *mut *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Callback to be invoked when Triton has finishing forming a batch.\n\n \\param userp The placeholder for backend to store and retrieve information\n about this pending batch.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONBACKEND_ModelBatchFinalize(
        userp: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
